// useAIAnalysis.js - AIåˆ†æåŠŸèƒ½çµ„åˆå¼API
import axios from 'axios'

export function useAIAnalysis() {
  // åŸ·è¡ŒèªéŸ³è­˜åˆ¥
  const performSpeechRecognition = async (audioBlob) => {
    console.log("ğŸ¯ é–‹å§‹èªéŸ³è­˜åˆ¥...")
    console.log("éŸ³é »Blobä¿¡æ¯:", {
      size: audioBlob?.size,
      type: audioBlob?.type,
    })

    const formData = new FormData()
    formData.append("file", audioBlob, "recording.wav")

    console.log("ğŸ“¤ ç™¼é€èªéŸ³è­˜åˆ¥è«‹æ±‚...")
    const response = await axios.post("/process_audio", formData, {
      headers: { "Content-Type": "multipart/form-data" },
      timeout: 60000, // 60ç§’è¶…æ—¶
    })

    console.log("ğŸ“¥ èªéŸ³è­˜åˆ¥éŸ¿æ‡‰:", response.data)

    if (response.data.transcript) {
      console.log("âœ… èªéŸ³è­˜åˆ¥æˆåŠŸ:", response.data.transcript)
      return response.data.transcript
    } else {
      console.error("âŒ èªéŸ³è­˜åˆ¥å¤±æ•—ï¼ŒéŸ¿æ‡‰:", response.data)
      throw new Error("èªéŸ³è­˜åˆ¥å¤±æ•—")
    }
  }

  // AIåˆ†æ (å¢å¼·ç‰ˆ - æ”¯æŒä¸Šä¸‹æ–‡)
  const performAIAnalysis = async (transcript, options = {}) => {
    const {
      selectedStaff = "admin",
      responseStyle = "friendly",
      conversationMode = "continuous",
      conversationContext = [],
      conversationRounds = 0
    } = options

    const response = await axios.post(
      "/voice_clone/generate_response_voice",
      {
        user_input: transcript,
        staff_code: selectedStaff,
        response_style: responseStyle,
        conversation_mode: conversationMode,
        conversation_context: conversationContext,
        conversation_round: conversationRounds,
      },
      {
        timeout: 120000,
      }
    )

    if (response.data.status === "success") {
      return {
        text: response.data.ai_analysis.response_text,
        sentiment: response.data.ai_analysis.sentiment,
        confidence: response.data.ai_analysis.confidence || 0.95,
        audioUrl: response.data.voice_output.audio_url,
      }
    } else {
      throw new Error(response.data.message || "AIåˆ†æå¤±æ•—")
    }
  }

  // é‡æ–°ç”Ÿæˆå›æ‡‰
  const regenerateResponse = async (message, lastUserMessage, options = {}) => {
    if (message.type !== "ai" || !lastUserMessage) {
      throw new Error("ç„¡æ³•é‡æ–°ç”Ÿæˆå›æ‡‰")
    }

    const aiResponse = await performAIAnalysis(lastUserMessage, options)
    return {
      ...message,
      text: aiResponse.text,
      audioUrl: aiResponse.audioUrl,
      sentiment: aiResponse.sentiment,
      confidence: aiResponse.confidence,
      time: new Date().toLocaleTimeString(),
    }
  }

  return {
    // æ–¹æ³•
    performSpeechRecognition,
    performAIAnalysis,
    regenerateResponse
  }
}