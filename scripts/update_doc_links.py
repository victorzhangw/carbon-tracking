#!/usr/bin/env python3
"""
Script to update internal links in markdown files after file reorganization.
Scans all .md files and updates relative links to reflect new file locations.
"""

import sys
import os
# Add project root to path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))
import os
import re
import json
from pathlib import Path
from typing import Dict, List, Tuple, Set

# Load migration log
def load_migration_log() -> Dict:
    """Load the migration log to get file movement mappings."""
    with open('migration_log.json', 'r', encoding='utf-8') as f:
        return json.load(f)

# Build path mapping from migration log
def build_path_mapping(migration_log: Dict) -> Dict[str, str]:
    """Build a mapping of old paths to new paths."""
    mapping = {}
    for migration in migration_log.get('migrations', []):
        old_path = migration['original_path']
        new_path = migration['new_path']
        mapping[old_path] = new_path
    return mapping

# Additional known file movements from tasks 4.2-4.6
ADDITIONAL_MAPPINGS = {
    # Guides (4.2)
    'é–‹å§‹ä½¿ç”¨_README.md': 'docs/guides/quick_start.md',
    'ç¢³æŽ’æ”¾è¿½è¹¤ç³»çµ±_ä½¿ç”¨èªªæ˜Ž.md': 'docs/guides/carbon_tracking_usage.md',
    'VOICE_CLONE_GUIDE.md': 'docs/guides/voice_clone_guide.md',
    'build_android_app.md': 'docs/guides/android_app_build.md',
    'deploy_to_render.md': 'docs/guides/deployment_guide.md',
    'å¿«é€Ÿåƒè€ƒå¡.md': 'docs/guides/å¿«é€Ÿåƒè€ƒå¡.md',
    'PWAæª¢æŸ¥æ¸…å–®.md': 'docs/guides/PWAæª¢æŸ¥æ¸…å–®.md',
    'éƒ¨ç½²æª¢æŸ¥æ¸…å–®.md': 'docs/guides/éƒ¨ç½²æª¢æŸ¥æ¸…å–®.md',
    'æœ€çµ‚æª¢æŸ¥æ¸…å–®.md': 'docs/guides/æœ€çµ‚æª¢æŸ¥æ¸…å–®.md',
    'ðŸš€å¿«é€Ÿå•Ÿå‹•æŒ‡å—.md': 'docs/guides/ðŸš€å¿«é€Ÿå•Ÿå‹•æŒ‡å—.md',
    'ðŸš€APKå»ºç½®èˆ‡ä¸Šæž¶å®Œæ•´æŒ‡å—.md': 'docs/guides/ðŸš€APKå»ºç½®èˆ‡ä¸Šæž¶å®Œæ•´æŒ‡å—.md',
    
    # Technical docs (4.3)
    'project-structure.md': 'docs/technical/architecture/project-structure.md',
    'SYSTEM_ARCHITECTURE_DIAGRAM.svg': 'docs/technical/architecture/SYSTEM_ARCHITECTURE_DIAGRAM.svg',
    'BACKEND_TECHNICAL_DOCUMENTATION.md': 'docs/technical/backend/BACKEND_TECHNICAL_DOCUMENTATION.md',
    'FRONTEND_TECHNICAL_DOCUMENTATION.md': 'docs/technical/frontend/FRONTEND_TECHNICAL_DOCUMENTATION.md',
    'ADVANCED_VOICE_SEPARATION_GUIDE.md': 'docs/technical/voice/ADVANCED_VOICE_SEPARATION_GUIDE.md',
    'AUDIO_SEPARATION_GUIDE.md': 'docs/technical/voice/AUDIO_SEPARATION_GUIDE.md',
    'VOICE_DATASET_VALIDATION_GUIDE.md': 'docs/technical/voice/VOICE_DATASET_VALIDATION_GUIDE.md',
    'GPT_SOVITS_FINE_TUNING_GUIDE.md': 'docs/technical/voice/GPT_SOVITS_FINE_TUNING_GUIDE.md',
    'VOICE_CLONE_SETUP.md': 'docs/technical/voice/VOICE_CLONE_SETUP.md',
    'MODEL_STORAGE_DEPLOYMENT_GUIDE.md': 'docs/technical/voice/MODEL_STORAGE_DEPLOYMENT_GUIDE.md',
    'MODEL_WEIGHTS_CONFIGURATION_GUIDE.md': 'docs/technical/voice/MODEL_WEIGHTS_CONFIGURATION_GUIDE.md',
    'VOLUME_BALANCE_SOLUTION.md': 'docs/technical/voice/VOLUME_BALANCE_SOLUTION.md',
    'NATURAL_VS_ADVANCED_COMPARISON.md': 'docs/technical/voice/NATURAL_VS_ADVANCED_COMPARISON.md',
    'setup_asr_environment.md': 'docs/technical/asr/setup_asr_environment.md',
    
    # Reports (4.4)
    'AI_CORE_MODULES_ARCHITECTURE_REPORT.md': 'docs/reports/AI_CORE_MODULES_ARCHITECTURE_REPORT.md',
    'VOICE_DATA_PROCESSING_AND_AI_MODULES_REPORT.md': 'docs/reports/VOICE_DATA_PROCESSING_AND_AI_MODULES_REPORT.md',
    'NOISE_REDUCTION_IMPROVEMENT_REPORT.md': 'docs/reports/NOISE_REDUCTION_IMPROVEMENT_REPORT.md',
    'MODULE_TESTING_REPORT.md': 'docs/reports/MODULE_TESTING_REPORT.md',
    'ELDERLY_VOICE_DATASET_VALIDATION_REPORT.md': 'docs/reports/ELDERLY_VOICE_DATASET_VALIDATION_REPORT.md',
    'CLEANUP_SUMMARY.md': 'docs/reports/CLEANUP_SUMMARY.md',
    'å„ªåŒ–å¾Œæ¨¡åž‹æˆæ•ˆæ¯”è¼ƒå ±å‘Š.md': 'docs/reports/å„ªåŒ–å¾Œæ¨¡åž‹æˆæ•ˆæ¯”è¼ƒå ±å‘Š.md',
    'å°ˆæ¥­ç³»çµ±é©—è­‰åŠASRæ”¹é€²æ•´åˆå ±å‘Š.md': 'docs/reports/å°ˆæ¥­ç³»çµ±é©—è­‰åŠASRæ”¹é€²æ•´åˆå ±å‘Š.md',
    'æŽ¨å»£æˆæžœæ‘˜è¦å ±å‘Š.md': 'docs/reports/æŽ¨å»£æˆæžœæ‘˜è¦å ±å‘Š.md',
    'ç¢³æŽ’æ”¾æ¸›å°‘æ•ˆç›Šåˆ†æž.md': 'docs/reports/ç¢³æŽ’æ”¾æ¸›å°‘æ•ˆç›Šåˆ†æž.md',
    'å°ˆæ¡ˆæŠ€è¡“åˆ†æžå ±å‘Š.md': 'docs/reports/å°ˆæ¡ˆæŠ€è¡“åˆ†æžå ±å‘Š.md',
    
    # Status docs (4.5)
    'âœ…ç¢³æŽ’æ”¾è¿½è¹¤ç³»çµ±_å»ºç½®å®Œæˆ.md': 'docs/status/completed/âœ…ç¢³æŽ’æ”¾è¿½è¹¤ç³»çµ±_å»ºç½®å®Œæˆ.md',
    'âœ…å·¥è™Ÿè‡ªå‹•å¸¶å‡ºå§“ååŠŸèƒ½å®Œæˆ.md': 'docs/status/completed/âœ…å·¥è™Ÿè‡ªå‹•å¸¶å‡ºå§“ååŠŸèƒ½å®Œæˆ.md',
    'âœ…æœå°‹èˆ‡ç¯©é¸åŠŸèƒ½å®Œæˆ.md': 'docs/status/completed/âœ…æœå°‹èˆ‡ç¯©é¸åŠŸèƒ½å®Œæˆ.md',
    'âœ…è¨˜éŒ„ç·¨è¼¯åˆªé™¤åŠŸèƒ½å®Œæˆ.md': 'docs/status/completed/âœ…è¨˜éŒ„ç·¨è¼¯åˆªé™¤åŠŸèƒ½å®Œæˆ.md',
    'âœ…è³‡æ–™åŒ¯å‡ºåŠŸèƒ½å®Œæˆ.md': 'docs/status/completed/âœ…è³‡æ–™åŒ¯å‡ºåŠŸèƒ½å®Œæˆ.md',
    'âœ…å„ªåŒ–å®Œæˆ_ç«‹å³æ¸¬è©¦.md': 'docs/status/completed/âœ…å„ªåŒ–å®Œæˆ_ç«‹å³æ¸¬è©¦.md',
    'âœ…PWA_Android_Appå®Œæˆ.md': 'docs/status/completed/âœ…PWA_Android_Appå®Œæˆ.md',
    'âœ…å®Œæˆå ±å‘Š_æ‰€æœ‰ä½è­‰è³‡æ–™å·²å°±ç·’.md': 'docs/status/completed/âœ…å®Œæˆå ±å‘Š_æ‰€æœ‰ä½è­‰è³‡æ–™å·²å°±ç·’.md',
    'ðŸŽ‰éƒ¨ç½²æˆåŠŸ_é–‹å§‹å»ºç½®APK.md': 'docs/status/deployment/ðŸŽ‰éƒ¨ç½²æˆåŠŸ_é–‹å§‹å»ºç½®APK.md',
    'ðŸŽ‰éƒ¨ç½²å®Œæˆ_ä¸‹ä¸€æ­¥è¡Œå‹•.md': 'docs/status/deployment/ðŸŽ‰éƒ¨ç½²å®Œæˆ_ä¸‹ä¸€æ­¥è¡Œå‹•.md',
    'ðŸŽ‰PWAè½‰æ›å®Œæˆ_å¿«é€Ÿé–‹å§‹.md': 'docs/status/completed/ðŸŽ‰PWAè½‰æ›å®Œæˆ_å¿«é€Ÿé–‹å§‹.md',
    'ðŸŽŠå®Œæ•´æ–¹æ¡ˆ_PWA+Androidå…¨éƒ¨å®Œæˆ.md': 'docs/status/completed/ðŸŽŠå®Œæ•´æ–¹æ¡ˆ_PWA+Androidå…¨éƒ¨å®Œæˆ.md',
    'ðŸŽŠPWAå®Œæ•´æ–¹æ¡ˆ_å…¨éƒ¨å®Œæˆ.md': 'docs/status/completed/ðŸŽŠPWAå®Œæ•´æ–¹æ¡ˆ_å…¨éƒ¨å®Œæˆ.md',
    'ðŸ”§ä¿®å¾©å®Œæˆ_ç­‰å¾…éƒ¨ç½².md': 'docs/status/deployment/ðŸ”§ä¿®å¾©å®Œæˆ_ç­‰å¾…éƒ¨ç½².md',
    'ðŸŒ¿æ·¡åŒ–ç¶ è‰²ä¸»é¡Œ+åˆ†é åŠŸèƒ½å®Œæˆ.md': 'docs/status/completed/ðŸŒ¿æ·¡åŒ–ç¶ è‰²ä¸»é¡Œ+åˆ†é åŠŸèƒ½å®Œæˆ.md',
    'ðŸŒ¿ç’°ä¿ç¶ è‰²ä¸»é¡Œå„ªåŒ–å®Œæˆ.md': 'docs/status/completed/ðŸŒ¿ç’°ä¿ç¶ è‰²ä¸»é¡Œå„ªåŒ–å®Œæˆ.md',
    'ðŸ“±è½‰æ›ç‚ºAndroid_AppæŒ‡å—.md': 'docs/status/completed/ðŸ“±è½‰æ›ç‚ºAndroid_AppæŒ‡å—.md',
    'ðŸ“±Android_Appå»ºç½®å®Œæˆ.md': 'docs/status/completed/ðŸ“±Android_Appå»ºç½®å®Œæˆ.md',
    'UIå„ªåŒ–å®Œæˆèªªæ˜Ž.md': 'docs/status/completed/UIå„ªåŒ–å®Œæˆèªªæ˜Ž.md',
    'å®Œæˆæ¸…å–®_ç¨½æ ¸ä½è­‰è³‡æ–™.md': 'docs/status/completed/å®Œæˆæ¸…å–®_ç¨½æ ¸ä½è­‰è³‡æ–™.md',
    
    # Other docs (4.6)
    'ç³»çµ±æ”¹é€²å»ºè­°.md': 'docs/ç³»çµ±æ”¹é€²å»ºè­°.md',
    'éƒ¨ç½²æž¶æ§‹å„ªåŒ–æ–¹æ¡ˆ.md': 'docs/technical/architecture/éƒ¨ç½²æž¶æ§‹å„ªåŒ–æ–¹æ¡ˆ.md',
    'éƒ¨ç½²æ¨¡å¼èªªæ˜Ž.md': 'docs/technical/architecture/éƒ¨ç½²æ¨¡å¼èªªæ˜Ž.md',
    'Renderéƒ¨ç½²å•é¡ŒæŽ’æŸ¥.md': 'docs/status/deployment/Renderéƒ¨ç½²å•é¡ŒæŽ’æŸ¥.md',
    'Android_AppåŠŸèƒ½ç›¸å®¹æ€§åˆ†æž.md': 'docs/technical/Android_AppåŠŸèƒ½ç›¸å®¹æ€§åˆ†æž.md',
    'PYTHON_313_COMPATIBILITY_FIX.md': 'docs/technical/PYTHON_313_COMPATIBILITY_FIX.md',
    'emotion_color_guide.md': 'docs/technical/voice/emotion_color_guide.md',
}

def find_all_markdown_files() -> List[Path]:
    """Find all markdown files in the project."""
    md_files = []
    for root, dirs, files in os.walk('.'):
        # Skip certain directories
        skip_dirs = {'.git', 'venv', 'node_modules', '__pycache__', '.kiro', 'backups', 'archive'}
        dirs[:] = [d for d in dirs if d not in skip_dirs]
        
        for file in files:
            if file.endswith('.md'):
                md_files.append(Path(root) / file)
    
    return md_files

def extract_markdown_links(content: str) -> List[Tuple[str, str]]:
    """Extract markdown links from content. Returns list of (full_match, link_path) tuples."""
    # Match markdown links: [text](path)
    pattern = r'\[([^\]]+)\]\(([^)]+)\)'
    matches = []
    
    for match in re.finditer(pattern, content):
        full_match = match.group(0)
        link_path = match.group(2)
        
        # Skip external links (http://, https://, mailto:, etc.)
        if not link_path.startswith(('http://', 'https://', 'mailto:', '#', 'ftp://')):
            matches.append((full_match, link_path))
    
    return matches

def normalize_path(path: str) -> str:
    """Normalize path for comparison."""
    # Remove leading ./ and trailing /
    path = path.lstrip('./')
    path = path.rstrip('/')
    # Handle URL fragments
    if '#' in path:
        path = path.split('#')[0]
    return path

def calculate_relative_path(from_file: Path, to_file: str) -> str:
    """Calculate relative path from one file to another."""
    from_dir = from_file.parent
    to_path = Path(to_file)
    
    try:
        rel_path = os.path.relpath(to_path, from_dir)
        # Convert Windows paths to Unix-style for markdown
        rel_path = rel_path.replace('\\', '/')
        return rel_path
    except ValueError:
        # If paths are on different drives (Windows), return absolute
        return to_file

def update_links_in_file(file_path: Path, path_mapping: Dict[str, str]) -> Tuple[int, List[str]]:
    """Update links in a single markdown file. Returns (num_updates, list_of_changes)."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except Exception as e:
        print(f"Error reading {file_path}: {e}")
        return 0, []
    
    original_content = content
    links = extract_markdown_links(content)
    updates = 0
    changes = []
    
    for full_match, link_path in links:
        # Extract the actual file path (remove anchors)
        clean_link = link_path.split('#')[0] if '#' in link_path else link_path
        anchor = '#' + link_path.split('#')[1] if '#' in link_path else ''
        
        # Normalize the link path
        normalized_link = normalize_path(clean_link)
        
        # Check if this file has been moved
        if normalized_link in path_mapping:
            new_path = path_mapping[normalized_link]
            
            # Calculate new relative path from current file to new location
            new_relative_path = calculate_relative_path(file_path, new_path)
            
            # Add anchor back if it existed
            new_link = new_relative_path + anchor
            
            # Create the new markdown link
            text = full_match.split('](')[0][1:]  # Extract link text
            new_full_match = f'[{text}]({new_link})'
            
            # Replace in content
            content = content.replace(full_match, new_full_match)
            updates += 1
            changes.append(f"  {link_path} â†’ {new_link}")
    
    # Write back if changes were made
    if updates > 0:
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
        except Exception as e:
            print(f"Error writing {file_path}: {e}")
            return 0, []
    
    return updates, changes

def main():
    """Main function to update all markdown links."""
    print("=" * 80)
    print("Updating Internal Links in Markdown Files")
    print("=" * 80)
    print()
    
    # Load migration log and build path mapping
    print("Loading migration log...")
    migration_log = load_migration_log()
    path_mapping = build_path_mapping(migration_log)
    
    # Add additional known mappings
    path_mapping.update(ADDITIONAL_MAPPINGS)
    
    print(f"Loaded {len(path_mapping)} file path mappings")
    print()
    
    # Find all markdown files
    print("Scanning for markdown files...")
    md_files = find_all_markdown_files()
    print(f"Found {len(md_files)} markdown files")
    print()
    
    # Update links in each file
    print("Updating links...")
    print("-" * 80)
    
    total_updates = 0
    files_updated = 0
    all_changes = []
    
    for md_file in md_files:
        updates, changes = update_links_in_file(md_file, path_mapping)
        if updates > 0:
            files_updated += 1
            total_updates += updates
            print(f"\nâœ“ {md_file}")
            for change in changes:
                print(change)
            all_changes.append({
                'file': str(md_file),
                'updates': updates,
                'changes': changes
            })
    
    print()
    print("-" * 80)
    print(f"\nSummary:")
    print(f"  Files scanned: {len(md_files)}")
    print(f"  Files updated: {files_updated}")
    print(f"  Total link updates: {total_updates}")
    print()
    
    # Save update log
    update_log = {
        'timestamp': '2025-11-11T12:00:00',
        'task': '4.7',
        'files_scanned': len(md_files),
        'files_updated': files_updated,
        'total_updates': total_updates,
        'changes': all_changes
    }
    
    with open('doc_links_update_log.json', 'w', encoding='utf-8') as f:
        json.dump(update_log, f, indent=2, ensure_ascii=False)
    
    print("Update log saved to: doc_links_update_log.json")
    print()
    print("=" * 80)
    print("Link update complete!")
    print("=" * 80)

if __name__ == '__main__':
    main()
