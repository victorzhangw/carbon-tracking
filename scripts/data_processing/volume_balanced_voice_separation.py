#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éŸ³é‡å¹³è¡¡çš„äººè²åˆ†é›¢å·¥å…·
è§£æ±ºåˆ†é›¢å¾Œå€‹äººéŸ³é‡å¿½é«˜å¿½ä½çš„å•é¡Œ
"""

import sys
import os
# Add project root to path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))
import os
import sys
import librosa
import soundfile as sf
import numpy as np
from scipy import signal
from scipy.ndimage import uniform_filter1d
import noisereduce as nr
from pydub import AudioSegment
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from pathlib import Path

class VolumeBalancedVoiceSeparator:
    def __init__(self, input_file):
        self.input_file = input_file
        self.output_dir = Path(input_file).parent / "volume_balanced_audio"
        self.output_dir.mkdir(exist_ok=True)
        
    def convert_to_wav(self):
        """è½‰æ›ç‚º WAV æ ¼å¼"""
        try:
            audio = AudioSegment.from_file(self.input_file)
            wav_path = self.output_dir / f"{Path(self.input_file).stem}_converted.wav"
            audio.export(wav_path, format="wav")
            print(f"âœ“ éŸ³é »å·²è½‰æ›ç‚º WAV æ ¼å¼: {wav_path}")
            return str(wav_path)
        except Exception as e:
            print(f"âœ— è½‰æ›å¤±æ•—: {e}")
            return None
    
    def load_audio(self, file_path):
        """è¼‰å…¥éŸ³é »æª”æ¡ˆ"""
        try:
            y, sr = librosa.load(file_path, sr=None)
            print(f"âœ“ éŸ³é »è¼‰å…¥æˆåŠŸ - æ¡æ¨£ç‡: {sr}Hz, é•·åº¦: {len(y)/sr:.2f}ç§’")
            return y, sr
        except Exception as e:
            print(f"âœ— éŸ³é »è¼‰å…¥å¤±æ•—: {e}")
            return None, None
    
    def gentle_noise_reduction(self, y, sr):
        """æº«å’Œçš„å™ªéŸ³æ¸›å°‘"""
        try:
            y_clean = nr.reduce_noise(
                y=y, 
                sr=sr, 
                stationary=True, 
                prop_decrease=0.15,
                n_std_thresh_stationary=2.0,
                n_fft=1024
            )
            print("âœ“ æº«å’Œå™ªéŸ³æ¸›å°‘å®Œæˆ")
            return y_clean
        except Exception as e:
            print(f"âœ— å™ªéŸ³æ¸›å°‘å¤±æ•—: {e}")
            return y
    
    def extract_speaker_features(self, y, sr):
        """æå–èªªè©±è€…ç‰¹å¾µï¼Œç”¨æ–¼æ›´æº–ç¢ºçš„åˆ†é›¢"""
        try:
            # ä½¿ç”¨è¼ƒå°çš„çª—å£ä»¥ç²å¾—æ›´å¥½çš„æ™‚é–“è§£æåº¦
            frame_length = 1024
            hop_length = 256
            
            # æå– MFCC ç‰¹å¾µ
            mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, 
                                       n_fft=frame_length, hop_length=hop_length)
            
            # æå–åŸºé »
            f0, voiced_flag, voiced_probs = librosa.pyin(y, 
                                                       fmin=librosa.note_to_hz('C2'), 
                                                       fmax=librosa.note_to_hz('C7'),
                                                       frame_length=frame_length)
            
            # æå–é »è­œé‡å¿ƒ
            spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr, 
                                                                 hop_length=hop_length)[0]
            
            # æå– RMS èƒ½é‡
            rms = librosa.feature.rms(y=y, frame_length=frame_length, 
                                    hop_length=hop_length)[0]
            
            print("âœ“ èªªè©±è€…ç‰¹å¾µæå–å®Œæˆ")
            return {
                'mfccs': mfccs,
                'f0': f0,
                'voiced_flag': voiced_flag,
                'spectral_centroids': spectral_centroids,
                'rms': rms,
                'hop_length': hop_length
            }
            
        except Exception as e:
            print(f"âœ— ç‰¹å¾µæå–å¤±æ•—: {e}")
            return None
    
    def intelligent_speaker_separation(self, y, sr, features, n_speakers=2):
        """æ™ºèƒ½èªªè©±è€…åˆ†é›¢ï¼ŒåŸºæ–¼å¤šç¶­ç‰¹å¾µ"""
        try:
            print(f"é–‹å§‹æ™ºèƒ½åˆ†é›¢ {n_speakers} å€‹èªªè©±è€…...")
            
            mfccs = features['mfccs']
            f0 = features['f0']
            spectral_centroids = features['spectral_centroids']
            rms = features['rms']
            
            # æº–å‚™èšé¡ç‰¹å¾µçŸ©é™£
            feature_matrix = []
            valid_indices = []
            
            # åªä½¿ç”¨æœ‰èªéŸ³æ´»å‹•çš„å¹€
            for i in range(mfccs.shape[1]):
                if i < len(rms) and rms[i] > np.percentile(rms, 20):  # èƒ½é‡é–¾å€¼
                    frame_features = []
                    
                    # MFCC ç‰¹å¾µ (å‰8å€‹ä¿‚æ•¸)
                    frame_features.extend(mfccs[:8, i])
                    
                    # åŸºé »ç‰¹å¾µ
                    if i < len(f0) and not np.isnan(f0[i]):
                        frame_features.append(f0[i])
                    else:
                        frame_features.append(0)
                    
                    # é »è­œé‡å¿ƒ
                    if i < len(spectral_centroids):
                        frame_features.append(spectral_centroids[i])
                    
                    # RMS èƒ½é‡
                    frame_features.append(rms[i])
                    
                    feature_matrix.append(frame_features)
                    valid_indices.append(i)
            
            if len(feature_matrix) < n_speakers:
                print("âœ— æœ‰æ•ˆèªéŸ³å¹€æ•¸ä¸è¶³")
                return None
            
            # æ¨™æº–åŒ–ç‰¹å¾µ
            feature_matrix = np.array(feature_matrix)
            scaler = StandardScaler()
            feature_matrix_scaled = scaler.fit_transform(feature_matrix)
            
            # K-means èšé¡
            kmeans = KMeans(n_clusters=n_speakers, random_state=42, n_init=20)
            speaker_labels = kmeans.fit_predict(feature_matrix_scaled)
            
            print(f"âœ“ æ™ºèƒ½èªªè©±è€…åˆ†é›¢å®Œæˆï¼Œè­˜åˆ¥å‡º {len(np.unique(speaker_labels))} å€‹èªªè©±è€…")
            
            return {
                'speaker_labels': speaker_labels,
                'valid_indices': valid_indices,
                'rms': rms,
                'hop_length': features['hop_length']
            }
            
        except Exception as e:
            print(f"âœ— èªªè©±è€…åˆ†é›¢å¤±æ•—: {e}")
            return None
    
    def create_volume_balanced_masks(self, y, sr, separation_result):
        """å‰µå»ºéŸ³é‡å¹³è¡¡çš„èªªè©±è€…é®ç½©"""
        try:
            speaker_labels = separation_result['speaker_labels']
            valid_indices = separation_result['valid_indices']
            rms = separation_result['rms']
            hop_length = separation_result['hop_length']
            
            n_frames = len(rms)
            n_speakers = len(np.unique(speaker_labels))
            
            # åˆå§‹åŒ–èªªè©±è€…é®ç½©
            speaker_masks = np.zeros((n_speakers, n_frames))
            speaker_energies = np.zeros((n_speakers, n_frames))
            
            # å¡«å……èªªè©±è€…æ¨™ç±¤å’Œèƒ½é‡
            label_idx = 0
            for frame_idx in range(n_frames):
                if frame_idx in valid_indices and label_idx < len(speaker_labels):
                    speaker_id = speaker_labels[label_idx]
                    speaker_masks[speaker_id, frame_idx] = 1.0
                    speaker_energies[speaker_id, frame_idx] = rms[frame_idx]
                    label_idx += 1
            
            # å¹³æ»‘é®ç½©
            for speaker_id in range(n_speakers):
                # ä½¿ç”¨è¼ƒå¤§çš„å¹³æ»‘çª—å£
                speaker_masks[speaker_id] = uniform_filter1d(speaker_masks[speaker_id], size=15)
                
                # æ‡‰ç”¨ sigmoid å‡½æ•¸ä½¿éæ¸¡æ›´å¹³æ»‘
                speaker_masks[speaker_id] = 1 / (1 + np.exp(-8 * (speaker_masks[speaker_id] - 0.5)))
                
                # ç¢ºä¿æœ€å°å€¼ï¼Œä¿æŒé€£çºŒæ€§
                speaker_masks[speaker_id] = np.maximum(speaker_masks[speaker_id], 0.05)
            
            print(f"âœ“ å‰µå»ºäº† {n_speakers} å€‹éŸ³é‡å¹³è¡¡é®ç½©")
            return speaker_masks, speaker_energies, hop_length
            
        except Exception as e:
            print(f"âœ— å‰µå»ºé®ç½©å¤±æ•—: {e}")
            return None, None, None
    
    def apply_volume_balanced_separation(self, y, sr, speaker_masks, speaker_energies, hop_length):
        """æ‡‰ç”¨éŸ³é‡å¹³è¡¡çš„èªªè©±è€…åˆ†é›¢"""
        try:
            # è¨ˆç®— STFT
            D = librosa.stft(y, hop_length=hop_length, n_fft=2048)
            magnitude, phase = np.abs(D), np.angle(D)
            
            separated_audios = []
            n_speakers = speaker_masks.shape[0]
            
            for speaker_id in range(n_speakers):
                # èª¿æ•´é®ç½©å¤§å°ä»¥åŒ¹é… STFT
                mask = speaker_masks[speaker_id]
                if len(mask) != magnitude.shape[1]:
                    mask = np.interp(np.linspace(0, len(mask)-1, magnitude.shape[1]), 
                                   np.arange(len(mask)), mask)
                
                # æ‡‰ç”¨é®ç½©
                masked_magnitude = magnitude * mask[np.newaxis, :]
                
                # é‡å»ºéŸ³é »
                masked_stft = masked_magnitude * np.exp(1j * phase)
                separated_audio = librosa.istft(masked_stft, hop_length=hop_length, length=len(y))
                
                separated_audios.append(separated_audio)
            
            print(f"âœ“ éŸ³é‡å¹³è¡¡åˆ†é›¢å®Œæˆï¼Œç”Ÿæˆ {len(separated_audios)} å€‹èªªè©±è€…éŸ³é »")
            return separated_audios
            
        except Exception as e:
            print(f"âœ— éŸ³é »åˆ†é›¢å¤±æ•—: {e}")
            return None 
   
    def normalize_speaker_volume(self, audio, target_rms=0.02):
        """æ­£è¦åŒ–èªªè©±è€…éŸ³é‡ï¼Œè§£æ±ºå¿½é«˜å¿½ä½å•é¡Œ"""
        try:
            # è¨ˆç®—ç•¶å‰ RMS
            current_rms = np.sqrt(np.mean(audio ** 2))
            
            if current_rms > 0:
                # è¨ˆç®—æ­£è¦åŒ–å› å­
                normalization_factor = target_rms / current_rms
                normalized_audio = audio * normalization_factor
            else:
                normalized_audio = audio
            
            # æ‡‰ç”¨å‹•æ…‹ç¯„åœå£“ç¸®ï¼Œå¹³æ»‘éŸ³é‡è®ŠåŒ–
            compressed_audio = self.apply_dynamic_range_compression(normalized_audio)
            
            print("âœ“ èªªè©±è€…éŸ³é‡æ­£è¦åŒ–å®Œæˆ")
            return compressed_audio
            
        except Exception as e:
            print(f"âœ— éŸ³é‡æ­£è¦åŒ–å¤±æ•—: {e}")
            return audio
    
    def apply_dynamic_range_compression(self, y, threshold=0.1, ratio=3.0, attack_time=0.01, release_time=0.1):
        """æ‡‰ç”¨å‹•æ…‹ç¯„åœå£“ç¸®ï¼Œå¹³æ»‘éŸ³é‡è®ŠåŒ–"""
        try:
            # è¨ˆç®—åŒ…çµ¡
            envelope = np.abs(y)
            
            # å¹³æ»‘åŒ…çµ¡
            sr = 16000  # å‡è¨­æ¡æ¨£ç‡
            attack_samples = int(attack_time * sr)
            release_samples = int(release_time * sr)
            
            # ç°¡åŒ–çš„å£“ç¸®å™¨
            compressed = y.copy()
            gain_reduction = np.ones_like(y)
            
            for i in range(len(envelope)):
                if envelope[i] > threshold:
                    # è¨ˆç®—å¢ç›Šæ¸›å°‘
                    excess = envelope[i] - threshold
                    gain_reduction[i] = threshold + excess / ratio
                    gain_reduction[i] = gain_reduction[i] / envelope[i] if envelope[i] > 0 else 1
                
            # å¹³æ»‘å¢ç›Šè®ŠåŒ–
            gain_reduction = uniform_filter1d(gain_reduction, size=attack_samples)
            
            # æ‡‰ç”¨å¢ç›Š
            compressed = y * gain_reduction
            
            return compressed
            
        except Exception as e:
            print(f"âœ— å‹•æ…‹ç¯„åœå£“ç¸®å¤±æ•—: {e}")
            return y
    
    def apply_volume_smoothing(self, y, sr, window_size=0.1):
        """æ‡‰ç”¨éŸ³é‡å¹³æ»‘ï¼Œæ¸›å°‘çªå…€çš„éŸ³é‡è®ŠåŒ–"""
        try:
            # è¨ˆç®—çŸ­æ™‚ RMS
            frame_length = int(window_size * sr)
            hop_length = frame_length // 4
            
            # è¨ˆç®— RMS åŒ…çµ¡
            rms = librosa.feature.rms(y=y, frame_length=frame_length, hop_length=hop_length)[0]
            
            # å¹³æ»‘ RMS
            smoothed_rms = uniform_filter1d(rms, size=5)
            
            # é‡æ–°æ¡æ¨£åˆ°åŸå§‹é•·åº¦
            time_frames = np.arange(len(rms)) * hop_length
            time_samples = np.arange(len(y))
            
            # æ’å€¼åˆ°æ¨£æœ¬ç´šåˆ¥
            smoothed_envelope = np.interp(time_samples, time_frames, smoothed_rms)
            
            # è¨ˆç®—åŸå§‹åŒ…çµ¡
            original_envelope = np.abs(y)
            original_envelope = uniform_filter1d(original_envelope, size=frame_length//10)
            
            # è¨ˆç®—å¢ç›Šèª¿æ•´
            gain_adjustment = np.ones_like(y)
            for i in range(len(y)):
                if original_envelope[i] > 0:
                    gain_adjustment[i] = smoothed_envelope[i] / original_envelope[i]
                    # é™åˆ¶å¢ç›Šè®ŠåŒ–ç¯„åœ
                    gain_adjustment[i] = np.clip(gain_adjustment[i], 0.5, 2.0)
            
            # æ‡‰ç”¨å¹³æ»‘å¢ç›Š
            y_smoothed = y * gain_adjustment
            
            print("âœ“ éŸ³é‡å¹³æ»‘è™•ç†å®Œæˆ")
            return y_smoothed
            
        except Exception as e:
            print(f"âœ— éŸ³é‡å¹³æ»‘å¤±æ•—: {e}")
            return y
    
    def save_audio(self, audio_data, sr, filename):
        """å„²å­˜éŸ³é »æª”æ¡ˆ"""
        try:
            output_path = self.output_dir / filename
            sf.write(output_path, audio_data, sr)
            print(f"âœ“ éŸ³é »å·²å„²å­˜: {output_path}")
            return str(output_path)
        except Exception as e:
            print(f"âœ— éŸ³é »å„²å­˜å¤±æ•—: {e}")
            return None
    
    def process_audio(self, n_speakers=2):
        """ä¸»è¦è™•ç†æµç¨‹ - éŸ³é‡å¹³è¡¡å„ªå…ˆ"""
        print(f"ğŸµ é–‹å§‹éŸ³é‡å¹³è¡¡éŸ³é »è™•ç† - åˆ†é›¢ {n_speakers} å€‹èªªè©±è€…")
        print("ğŸ”Š å°ˆé–€è§£æ±ºéŸ³é‡å¿½é«˜å¿½ä½å•é¡Œ")
        print("=" * 60)
        print(f"è™•ç†æª”æ¡ˆ: {self.input_file}")
        
        # 1. è½‰æ›æ ¼å¼
        wav_file = self.convert_to_wav()
        if not wav_file:
            return False
        
        # 2. è¼‰å…¥éŸ³é »
        y, sr = self.load_audio(wav_file)
        if y is None:
            return False
        
        # 3. æº«å’Œçš„å™ªéŸ³æ¸›å°‘
        y_clean = self.gentle_noise_reduction(y, sr)
        
        # 4. æå–èªªè©±è€…ç‰¹å¾µ
        features = self.extract_speaker_features(y_clean, sr)
        if features is None:
            return False
        
        # 5. æ™ºèƒ½èªªè©±è€…åˆ†é›¢
        separation_result = self.intelligent_speaker_separation(y_clean, sr, features, n_speakers)
        if separation_result is None:
            # å¦‚æœåˆ†é›¢å¤±æ•—ï¼Œè‡³å°‘æä¾›éŸ³é‡å¹³è¡¡çš„æ•´é«”éŸ³é »
            y_balanced = self.normalize_speaker_volume(y_clean)
            y_smoothed = self.apply_volume_smoothing(y_balanced, sr)
            
            results = {}
            results['original'] = self.save_audio(y, sr, "01_original.wav")
            results['volume_balanced'] = self.save_audio(y_smoothed, sr, "02_volume_balanced.wav")
            
            print("\n" + "=" * 60)
            print("âš ï¸ èªªè©±è€…åˆ†é›¢å¤±æ•—ï¼Œä½†å·²ç”ŸæˆéŸ³é‡å¹³è¡¡ç‰ˆæœ¬")
            return True
        
        # 6. å‰µå»ºéŸ³é‡å¹³è¡¡é®ç½©
        speaker_masks, speaker_energies, hop_length = self.create_volume_balanced_masks(
            y_clean, sr, separation_result)
        if speaker_masks is None:
            return False
        
        # 7. æ‡‰ç”¨éŸ³é‡å¹³è¡¡åˆ†é›¢
        separated_audios = self.apply_volume_balanced_separation(
            y_clean, sr, speaker_masks, speaker_energies, hop_length)
        if separated_audios is None:
            return False
        
        # 8. å°æ¯å€‹èªªè©±è€…æ‡‰ç”¨éŸ³é‡è™•ç†
        balanced_speakers = []
        for i, speaker_audio in enumerate(separated_audios):
            # æ­£è¦åŒ–éŸ³é‡
            normalized = self.normalize_speaker_volume(speaker_audio)
            # æ‡‰ç”¨éŸ³é‡å¹³æ»‘
            smoothed = self.apply_volume_smoothing(normalized, sr)
            balanced_speakers.append(smoothed)
        
        # 9. å„²å­˜çµæœ
        results = {}
        results['original'] = self.save_audio(y, sr, "01_original.wav")
        results['cleaned'] = self.save_audio(y_clean, sr, "02_noise_reduced.wav")
        
        # å„²å­˜éŸ³é‡å¹³è¡¡çš„èªªè©±è€…éŸ³é »
        for i, (raw_audio, balanced_audio) in enumerate(zip(separated_audios, balanced_speakers)):
            speaker_num = i + 1
            results[f'speaker_{speaker_num}_raw'] = self.save_audio(
                raw_audio, sr, f"03_speaker_{speaker_num}_raw.wav"
            )
            results[f'speaker_{speaker_num}_balanced'] = self.save_audio(
                balanced_audio, sr, f"04_speaker_{speaker_num}_volume_balanced.wav"
            )
        
        # å‰µå»ºæ•´é«”éŸ³é‡å¹³è¡¡ç‰ˆæœ¬
        if len(balanced_speakers) >= 2:
            mixed_balanced = np.zeros_like(balanced_speakers[0])
            for balanced in balanced_speakers:
                mixed_balanced += balanced * 0.5  # å¹³å‡æ··åˆ
            results['mixed_balanced'] = self.save_audio(
                mixed_balanced, sr, "05_all_speakers_volume_balanced.wav"
            )
        
        print("\n" + "=" * 60)
        print("ğŸ‰ éŸ³é‡å¹³è¡¡è™•ç†å®Œæˆï¼è¼¸å‡ºæª”æ¡ˆ:")
        for key, path in results.items():
            if path:
                print(f"  ğŸ“ {key}: {Path(path).name}")
        
        print(f"\nğŸ’¡ æ¨è–¦ä½¿ç”¨ (éŸ³é‡å¹³è¡¡):")
        print(f"  ğŸ”Š èªªè©±è€…1: 04_speaker_1_volume_balanced.wav")
        print(f"  ğŸ”Š èªªè©±è€…2: 04_speaker_2_volume_balanced.wav")
        print(f"  ğŸ”Š æ•´é«”å¹³è¡¡: 05_all_speakers_volume_balanced.wav")
        
        print(f"\nğŸŒŸ ç‰¹é»: è§£æ±ºéŸ³é‡å¿½é«˜å¿½ä½ï¼Œä¿æŒç©©å®šéŸ³é‡")
        
        return True

def main():
    input_file = r"D:\python\Flask-AICares\TTS\03041966.m4a"
    
    print("ğŸµ éŸ³é‡å¹³è¡¡äººè²åˆ†é›¢å·¥å…·")
    print("=" * 60)
    print("ğŸ”Š å°ˆé–€è§£æ±ºçš„å•é¡Œ:")
    print("  â€¢ åˆ†é›¢å¾Œå€‹äººéŸ³é‡å¿½é«˜å¿½ä½")
    print("  â€¢ éŸ³é‡ä¸ç©©å®š")
    print("  â€¢ å‹•æ…‹ç¯„åœéå¤§")
    print("  â€¢ çªå…€çš„éŸ³é‡è®ŠåŒ–")
    print("=" * 60)
    
    if not os.path.exists(input_file):
        print(f"âŒ æª”æ¡ˆä¸å­˜åœ¨: {input_file}")
        return False
    
    try:
        separator = VolumeBalancedVoiceSeparator(input_file)
        success = separator.process_audio(n_speakers=2)
        
        if success:
            print("\nğŸ‰ éŸ³é‡å¹³è¡¡è™•ç†å®Œæˆï¼")
            print(f"ğŸ“ è¼¸å‡ºç›®éŒ„: {separator.output_dir}")
            print("\nğŸ“‹ æª”æ¡ˆèªªæ˜:")
            print("  ğŸ”Š 04_speaker_X_volume_balanced.wav - éŸ³é‡å¹³è¡¡çš„èªªè©±è€…ï¼ˆæ¨è–¦ï¼‰")
            print("  ğŸ“Š 03_speaker_X_raw.wav - åŸå§‹åˆ†é›¢ç‰ˆæœ¬ï¼ˆå°æ¯”ç”¨ï¼‰")
            print("  ğŸ”Š 05_all_speakers_volume_balanced.wav - æ•´é«”éŸ³é‡å¹³è¡¡ç‰ˆ")
            
            print("\nğŸ’¡ æ”¹é€²æ•ˆæœ:")
            print("  â€¢ ç©©å®šçš„éŸ³é‡æ°´å¹³")
            print("  â€¢ å¹³æ»‘çš„éŸ³é‡éæ¸¡")
            print("  â€¢ å‹•æ…‹ç¯„åœå£“ç¸®")
            print("  â€¢ æ¶ˆé™¤çªå…€è®ŠåŒ–")
            
            return True
        else:
            print("\nâŒ è™•ç†å¤±æ•—")
            return False
            
    except Exception as e:
        print(f"\nâŒ è™•ç†éŒ¯èª¤: {e}")
        return False

if __name__ == "__main__":
    success = main()
    if not success:
        sys.exit(1)