# P0-1 ASR é–‹ç™¼ç’°å¢ƒè¨­ç½®æŒ‡å—

## ç’°å¢ƒéœ€æ±‚

### ç¡¬é«”éœ€æ±‚

- **CPU**: Intel i5 æˆ–ä»¥ä¸Šï¼ˆæ¨è–¦ i7/i9ï¼‰
- **RAM**: æœ€å°‘ 16GBï¼ˆæ¨è–¦ 32GBï¼‰
- **GPU**: NVIDIA GPU with CUDA supportï¼ˆæ¨è–¦ RTX 3060 æˆ–ä»¥ä¸Šï¼‰
  - VRAM: æœ€å°‘ 6GBï¼ˆæ¨è–¦ 12GB+ï¼‰
- **å„²å­˜**: æœ€å°‘ 50GB å¯ç”¨ç©ºé–“

### è»Ÿé«”éœ€æ±‚

- **ä½œæ¥­ç³»çµ±**: Windows 10/11, Linux, macOS
- **Python**: 3.8 - 3.11ï¼ˆæ¨è–¦ 3.10ï¼‰
- **CUDA**: 11.8 æˆ– 12.1ï¼ˆå¦‚æœä½¿ç”¨ GPUï¼‰
- **cuDNN**: å°æ‡‰ CUDA ç‰ˆæœ¬

---

## å®‰è£æ­¥é©Ÿ

### 1. æª¢æŸ¥ Python ç‰ˆæœ¬

```bash
python --version
# æ‡‰è©²é¡¯ç¤º Python 3.8.x åˆ° 3.11.x
```

### 2. å‰µå»ºè™›æ“¬ç’°å¢ƒï¼ˆæ¨è–¦ï¼‰

```bash
# ä½¿ç”¨ venv
python -m venv venv-asr

# å•Ÿå‹•è™›æ“¬ç’°å¢ƒ
# Windows:
venv-asr\Scripts\activate
# Linux/macOS:
source venv-asr/bin/activate
```

### 3. å‡ç´š pip

```bash
python -m pip install --upgrade pip
```

### 4. å®‰è£ PyTorchï¼ˆæ ¹æ“šæ‚¨çš„ç³»çµ±ï¼‰

#### æœ‰ NVIDIA GPUï¼ˆæ¨è–¦ï¼‰

```bash
# CUDA 11.8
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# CUDA 12.1
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

#### åƒ… CPU

```bash
pip install torch torchvision torchaudio
```

### 5. é©—è­‰ PyTorch å®‰è£

```python
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}'); print(f'CUDA version: {torch.version.cuda if torch.cuda.is_available() else \"N/A\"}')"
```

é æœŸè¼¸å‡ºï¼š

```
PyTorch: 2.1.0+cu118
CUDA available: True
CUDA version: 11.8
```

### 6. å®‰è£ ASR ä¾è³´

```bash
pip install -r requirements-asr.txt
```

### 7. ä¸‹è¼‰é è¨“ç·´æ¨¡å‹

#### Whisper æ¨¡å‹

```python
# åŸ·è¡Œä»¥ä¸‹ Python è…³æœ¬ä¸‹è¼‰ Whisper æ¨¡å‹
python -c "import whisper; whisper.load_model('large-v3')"
```

æ¨¡å‹æœƒä¸‹è¼‰åˆ°ï¼š

- Windows: `C:\Users\<username>\.cache\whisper\`
- Linux/macOS: `~/.cache/whisper/`

#### FunASR æ¨¡å‹

```python
# åŸ·è¡Œä»¥ä¸‹ Python è…³æœ¬ä¸‹è¼‰ FunASR æ¨¡å‹
python -c "from funasr import AutoModel; AutoModel(model='paraformer-zh')"
```

æ¨¡å‹æœƒä¸‹è¼‰åˆ°ï¼š

- `~/.cache/modelscope/`

### 8. é©—è­‰å®‰è£

å‰µå»ºæ¸¬è©¦è…³æœ¬ `test_asr_setup.py`:

```python
import torch
import whisper
from funasr import AutoModel
import librosa
import numpy as np

print("=== ASR ç’°å¢ƒé©—è­‰ ===\n")

# 1. PyTorch
print(f"âœ“ PyTorch: {torch.__version__}")
print(f"âœ“ CUDA available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"âœ“ CUDA version: {torch.version.cuda}")
    print(f"âœ“ GPU: {torch.cuda.get_device_name(0)}")
    print(f"âœ“ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")

# 2. Whisper
print("\n--- Whisper ---")
try:
    model = whisper.load_model("base")  # ä½¿ç”¨å°æ¨¡å‹æ¸¬è©¦
    print("âœ“ Whisper æ¨¡å‹è¼‰å…¥æˆåŠŸ")
    del model
except Exception as e:
    print(f"âœ— Whisper éŒ¯èª¤: {e}")

# 3. FunASR
print("\n--- FunASR ---")
try:
    model = AutoModel(model="paraformer-zh")
    print("âœ“ FunASR æ¨¡å‹è¼‰å…¥æˆåŠŸ")
    del model
except Exception as e:
    print(f"âœ— FunASR éŒ¯èª¤: {e}")

# 4. Librosa
print("\n--- Librosa ---")
try:
    # å‰µå»ºæ¸¬è©¦éŸ³é »
    sr = 16000
    duration = 1
    t = np.linspace(0, duration, sr * duration)
    audio = np.sin(2 * np.pi * 440 * t)  # 440Hz æ­£å¼¦æ³¢

    # æ¸¬è©¦ç‰¹å¾µæå–
    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)
    print(f"âœ“ Librosa å·¥ä½œæ­£å¸¸ (MFCC shape: {mfccs.shape})")
except Exception as e:
    print(f"âœ— Librosa éŒ¯èª¤: {e}")

print("\n=== é©—è­‰å®Œæˆ ===")
```

åŸ·è¡Œæ¸¬è©¦ï¼š

```bash
python test_asr_setup.py
```

---

## å¸¸è¦‹å•é¡Œ

### Q1: CUDA ä¸å¯ç”¨

**å•é¡Œ**: `torch.cuda.is_available()` è¿”å› `False`

**è§£æ±ºæ–¹æ¡ˆ**:

1. ç¢ºèªå·²å®‰è£ NVIDIA é©…å‹•ç¨‹å¼
2. ç¢ºèªå®‰è£äº†å°æ‡‰ç‰ˆæœ¬çš„ CUDA Toolkit
3. é‡æ–°å®‰è£ PyTorch GPU ç‰ˆæœ¬

### Q2: Whisper æ¨¡å‹ä¸‹è¼‰å¤±æ•—

**å•é¡Œ**: ç¶²è·¯é€£æ¥å•é¡Œå°è‡´æ¨¡å‹ä¸‹è¼‰å¤±æ•—

**è§£æ±ºæ–¹æ¡ˆ**:

1. ä½¿ç”¨ä»£ç†æˆ– VPN
2. æ‰‹å‹•ä¸‹è¼‰æ¨¡å‹æ–‡ä»¶ä¸¦æ”¾ç½®åˆ°å¿«å–ç›®éŒ„
3. ä½¿ç”¨åœ‹å…§é¡åƒæº

### Q3: FunASR æ¨¡å‹ä¸‹è¼‰æ…¢

**å•é¡Œ**: ModelScope ä¸‹è¼‰é€Ÿåº¦æ…¢

**è§£æ±ºæ–¹æ¡ˆ**:

```bash
# è¨­ç½® ModelScope é¡åƒ
export MODELSCOPE_CACHE=~/.cache/modelscope
```

### Q4: è¨˜æ†¶é«”ä¸è¶³

**å•é¡Œ**: è¼‰å…¥å¤§æ¨¡å‹æ™‚è¨˜æ†¶é«”ä¸è¶³

**è§£æ±ºæ–¹æ¡ˆ**:

1. ä½¿ç”¨è¼ƒå°çš„æ¨¡å‹ï¼ˆå¦‚ Whisper base è€Œé largeï¼‰
2. æ¸›å°‘æ‰¹æ¬¡å¤§å°
3. ä½¿ç”¨æ¨¡å‹é‡åŒ–

### Q5: ImportError

**å•é¡Œ**: ç¼ºå°‘æŸäº›ä¾è³´

**è§£æ±ºæ–¹æ¡ˆ**:

```bash
pip install --upgrade -r requirements-asr.txt
```

---

## æ¨¡å‹å¤§å°åƒè€ƒ

### Whisper æ¨¡å‹

| æ¨¡å‹     | åƒæ•¸é‡ | å¤§å°  | VRAM éœ€æ±‚ |
| -------- | ------ | ----- | --------- |
| tiny     | 39M    | 150MB | ~1GB      |
| base     | 74M    | 290MB | ~1GB      |
| small    | 244M   | 950MB | ~2GB      |
| medium   | 769M   | 3GB   | ~5GB      |
| large-v3 | 1550M  | 6GB   | ~10GB     |

### FunASR æ¨¡å‹

| æ¨¡å‹          | å¤§å°   | VRAM éœ€æ±‚ |
| ------------- | ------ | --------- |
| paraformer-zh | ~220MB | ~2GB      |

---

## é–‹ç™¼å·¥å…·æ¨è–¦

### IDE

- **VS Code** + Python æ“´å±•
- **PyCharm Professional**

### èª¿è©¦å·¥å…·

- **Jupyter Notebook** - äº’å‹•å¼é–‹ç™¼
- **TensorBoard** - æ¨¡å‹è¨“ç·´å¯è¦–åŒ–

### æ€§èƒ½åˆ†æ

- **nvidia-smi** - GPU ç›£æ§
- **htop** - CPU/è¨˜æ†¶é«”ç›£æ§

---

## ä¸‹ä¸€æ­¥

ç’°å¢ƒè¨­ç½®å®Œæˆå¾Œï¼Œæ‚¨å¯ä»¥ï¼š

1. åŸ·è¡Œ `test_asr_setup.py` é©—è­‰ç’°å¢ƒ
2. é–‹å§‹å¯¦ç¾ä»»å‹™ 2.1ï¼ˆASR Coordinator åŸºç¤æ¡†æ¶ï¼‰
3. æŸ¥çœ‹è¨­è¨ˆæ–‡æª” `.kiro/specs/p0-dual-engine-asr/design.md`

---

**è¨­ç½®å®Œæˆï¼** ğŸ‰

å¦‚æœ‰å•é¡Œï¼Œè«‹åƒè€ƒï¼š

- Whisper æ–‡æª”: https://github.com/openai/whisper
- FunASR æ–‡æª”: https://github.com/alibaba-damo-academy/FunASR
- PyTorch æ–‡æª”: https://pytorch.org/docs/
