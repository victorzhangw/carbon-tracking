# AI å®¢æœèªéŸ³å…‹éš†ç³»çµ± - å¾Œç«¯æŠ€è¡“èªªæ˜æ–‡ä»¶

## ğŸ“‹ ç³»çµ±æ¦‚è¿°

æœ¬ç³»çµ±æ˜¯ä¸€å€‹åŸºæ–¼ Flask çš„ AI å®¢æœèªéŸ³å…‹éš†èˆ‡æƒ…ç·’è­˜åˆ¥ç³»çµ±ï¼Œæä¾›èªéŸ³éŒ„è£½ã€æƒ…ç·’åˆ†æã€èªéŸ³åˆæˆã€ä»¥åŠæ™ºèƒ½å°è©±ç­‰åŠŸèƒ½ã€‚

## ğŸ—ï¸ æŠ€è¡“æ¶æ§‹

### æ ¸å¿ƒæŠ€è¡“æ£§

- **Web æ¡†æ¶**: Flask 3.1.0
- **è³‡æ–™åº«**: SQLite3 (å¯æ“´å±•è‡³ PostgreSQL/MySQL)
- **éŸ³é »è™•ç†**: librosa, pydub, soundfile
- **æ©Ÿå™¨å­¸ç¿’**: scikit-learn, torch, transformers
- **èªéŸ³è­˜åˆ¥**: SpeechRecognition
- **API è¨­è¨ˆ**: RESTful API
- **èº«ä»½é©—è­‰**: Flask-JWT-Extended
- **è·¨åŸŸæ”¯æ´**: Flask-CORS

### ç³»çµ±æ¶æ§‹åœ–

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   å‰ç«¯ Vue.js   â”‚â”€â”€â”€â–¶â”‚  Flask API å±¤   â”‚â”€â”€â”€â–¶â”‚   æœå‹™å±¤ (AI)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                        â”‚
                                â–¼                        â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   è³‡æ–™åº«å±¤      â”‚    â”‚   å¤–éƒ¨ AI æœå‹™  â”‚
                       â”‚   (SQLite)      â”‚    â”‚   (OpenAIç­‰)    â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½æ¨¡çµ„

### 1. éŸ³é »ç®¡ç†æ¨¡çµ„ (`routes/audio.py`)

#### æŠ€è¡“è·¯ç·š

- **æª”æ¡ˆä¸Šå‚³**: ä½¿ç”¨ `werkzeug.utils.secure_filename` ç¢ºä¿æª”æ¡ˆå®‰å…¨
- **æª”æ¡ˆå„²å­˜**: æŒ‰å®¢æœå°ˆå“¡ä»£è™Ÿåˆ†é¡å„²å­˜
- **éŸ³é »è™•ç†**: ä½¿ç”¨ `librosa` æå–éŸ³é »æ™‚é•·å’ŒåŸºæœ¬è³‡è¨Š
- **æª”æ¡ˆç®¡ç†**: æ”¯æ´ CRUD æ“ä½œå’Œæª”æ¡ˆä¸²æµ

#### é—œéµ API ç«¯é»

```python
POST /api/audio/upload          # éŸ³é »ä¸Šå‚³
GET  /api/audio                 # éŸ³é »åˆ—è¡¨ (åˆ†é )
GET  /api/audio/<id>            # å–®å€‹éŸ³é »è©³æƒ…
PUT  /api/audio/<id>            # æ›´æ–°éŸ³é »è³‡è¨Š
DELETE /api/audio/<id>          # åˆªé™¤éŸ³é »
GET  /api/audio/stream/<id>     # éŸ³é »ä¸²æµæ’­æ”¾
GET  /api/audio/download/<id>   # éŸ³é »ä¸‹è¼‰
```

#### è³‡æ–™ä¸²æ¥æ¨¡å¼

```python
# ä¸Šå‚³æµç¨‹
FormData â†’ æª”æ¡ˆé©—è­‰ â†’ å®‰å…¨å„²å­˜ â†’ è³‡æ–™åº«è¨˜éŒ„ â†’ å›å‚³çµæœ

# è³‡æ–™åº«çµæ§‹
audio: {
    id: UUID,
    name: String,
    staff_id: UUID,
    file_path: String,
    duration: Integer,
    file_size: String,
    emotion: String,           # æƒ…ç·’åˆ†æçµæœ
    emotion_confidence: Float, # ç½®ä¿¡åº¦
    created_at: Timestamp
}
```

### 2. æƒ…ç·’è­˜åˆ¥æ¨¡çµ„ (`services/emotion_recognition.py`)

#### æŠ€è¡“è·¯ç·š

**åŸºç¤ç‰ˆæœ¬ (é è¨­)**:

- **éŸ³é »ç‰¹å¾µæå–**: ä½¿ç”¨ librosa æå– MFCCã€å…‰è­œè³ªå¿ƒã€é›¶äº¤å‰ç‡ã€ç¯€æ‹
- **åˆ†é¡æ¼”ç®—æ³•**: åŸºæ–¼è¦å‰‡çš„ç°¡å–®åˆ†é¡å™¨
- **æ”¯æ´æƒ…ç·’**: 6 ç¨®åŸºç¤æƒ…ç·’ (happy, sad, angry, neutral, fear, surprise)

**é€²éšç‰ˆæœ¬ (å¯é¸)**:

- **æ·±åº¦å­¸ç¿’æ¨¡å‹**: Wav2Vec2ForSequenceClassification
- **é è¨“ç·´æ¨¡å‹**: `ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition`
- **æ”¯æ´æƒ…ç·’**: 8 ç¨®é€²éšæƒ…ç·’ (angry, calm, disgust, fearful, happy, neutral, sad, surprised)

#### æ¼”ç®—æ³•å¯¦ä½œ

**åŸºç¤ç‰ˆæœ¬æ¼”ç®—æ³•**:

```python
def _simple_emotion_detection(self, audio_path):
    # 1. éŸ³é »è¼‰å…¥
    y, sr = librosa.load(audio_path, duration=10)

    # 2. ç‰¹å¾µæå–
    rms_energy = np.sqrt(np.mean(y**2))
    zero_crossing_rate = np.mean(librosa.feature.zero_crossing_rate(y))
    spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))
    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)

    # 3. è¦å‰‡åˆ†é¡
    if rms_energy > 0.02 and tempo > 120:
        return "happy"
    elif rms_energy < 0.01 and tempo < 90:
        return "sad"
    # ... å…¶ä»–è¦å‰‡
```

**é€²éšç‰ˆæœ¬æ¼”ç®—æ³•**:

```python
def predict_emotion(self, audio_path):
    # 1. éŸ³é »é è™•ç†
    speech, sample_rate = librosa.load(audio_path, sr=16000)

    # 2. ç‰¹å¾µæå– (Wav2Vec2)
    inputs = self.feature_extractor(speech, sampling_rate=sample_rate,
                                   return_tensors="pt", padding=True)

    # 3. æ¨¡å‹æ¨ç†
    with torch.no_grad():
        logits = self.model(**inputs).logits
        probabilities = torch.nn.functional.softmax(logits, dim=-1)
        predicted_id = torch.argmax(logits, dim=-1).item()

    return self.emotion_labels[predicted_id]
```

#### API ç«¯é»

```python
POST /api/emotion/analyze/<audio_id>      # åˆ†ææŒ‡å®šéŸ³æª”
POST /api/emotion/batch-analyze           # æ‰¹é‡åˆ†æ
POST /api/emotion/upload-and-analyze      # ä¸Šå‚³ä¸¦åˆ†æ
GET  /api/emotion/models/status           # æ¨¡å‹ç‹€æ…‹
POST /api/emotion/models/load-advanced    # è¼‰å…¥é€²éšæ¨¡å‹
```

### 3. èªéŸ³åˆæˆæ¨¡çµ„ (`routes/voice_clone.py`)

#### æŠ€è¡“è·¯ç·š

- **èªéŸ³å…‹éš†**: æ•´åˆ GPT-SoVITS-v2pro æ·±åº¦å­¸ç¿’æ¨¡å‹
- **æ¨¡å‹å¾®èª¿**: åŸºæ–¼å®¢æœå°ˆå“¡èªéŸ³æ•¸æ“šé€²è¡Œå€‹äººåŒ–è¨“ç·´
- **èªéŸ³ç”Ÿæˆ**: æ”¯æ´å¤šç¨®èªèª¿å’Œé¢¨æ ¼çš„é«˜å“è³ªèªéŸ³åˆæˆ
- **éŸ³é »å¾Œè™•ç†**: æ ¼å¼è½‰æ›ã€é™å™ªå’Œå“è³ªå„ªåŒ–

#### GPT-SoVITS æ¶æ§‹åˆ†æ

**æ¨¡å‹æ¶æ§‹** (åŸºæ–¼ `D:\python\GPT-SoVITS-v2pro-20250604`):

```
GPT-SoVITS-v2pro/
â”œâ”€â”€ GPT_SoVITS/           # æ ¸å¿ƒæ¨¡å‹ä»£ç¢¼
â”‚   â”œâ”€â”€ module/           # ç¥ç¶“ç¶²è·¯æ¨¡çµ„
â”‚   â”œâ”€â”€ text/            # æ–‡å­—è™•ç†
â”‚   â”œâ”€â”€ AR.py            # è‡ªå›æ­¸æ¨¡å‹
â”‚   â””â”€â”€ SynthesizerTrn.py # VITS åˆæˆå™¨
â”œâ”€â”€ tools/               # å·¥å…·è…³æœ¬
â”‚   â”œâ”€â”€ asr/            # è‡ªå‹•èªéŸ³è­˜åˆ¥
â”‚   â”œâ”€â”€ uvr5/           # äººè²åˆ†é›¢
â”‚   â””â”€â”€ slice_audio.py  # éŸ³é »åˆ‡ç‰‡
â”œâ”€â”€ configs/            # é…ç½®æª”æ¡ˆ
â”œâ”€â”€ pretrained_models/  # é è¨“ç·´æ¨¡å‹
â””â”€â”€ logs/              # è¨“ç·´æ—¥èªŒ
```

**æŠ€è¡“åŸç†**:

- **GPT æ¨¡å‹**: åŸºæ–¼ Transformer çš„èªç¾©ç†è§£å’ŒéŸ»å¾‹é æ¸¬
- **SoVITS æ¨¡å‹**: æ”¹é€²ç‰ˆ VITSï¼Œæ”¯æ´é›¶æ¨£æœ¬èªéŸ³å…‹éš†
- **èªªè©±äººç·¨ç¢¼**: é€šéåƒè€ƒéŸ³é »å­¸ç¿’èªªè©±äººç‰¹å¾µ
- **æƒ…æ„Ÿæ§åˆ¶**: æ”¯æ´æƒ…æ„Ÿå’Œèªèª¿çš„ç²¾ç´°æ§åˆ¶

#### GPT-SoVITS å¾®èª¿å·¥ä½œæµç¨‹

**1. ç’°å¢ƒæº–å‚™éšæ®µ**

```python
# GPT-SoVITS ç’°å¢ƒé…ç½®
class GPTSoVITSEnvironment:
    def __init__(self, base_path="D:/python/GPT-SoVITS-v2pro-20250604"):
        self.base_path = base_path
        self.python_path = f"{base_path}/runtime/python.exe"
        self.config_path = f"{base_path}/configs"
        self.pretrained_path = f"{base_path}/pretrained_models"

    def setup_environment(self):
        """è¨­ç½® GPT-SoVITS ç’°å¢ƒ"""
        # 1. æª¢æŸ¥ CUDA ç’°å¢ƒ
        if not torch.cuda.is_available():
            raise RuntimeError("éœ€è¦ CUDA æ”¯æ´é€²è¡Œæ¨¡å‹è¨“ç·´")

        # 2. è¼‰å…¥é è¨“ç·´æ¨¡å‹
        self.download_pretrained_models()

        # 3. è¨­ç½®ç’°å¢ƒè®Šæ•¸
        os.environ['PYTHONPATH'] = self.base_path
        os.environ['CUDA_VISIBLE_DEVICES'] = '0'

        return True
```

**2. æ•¸æ“šé è™•ç†éšæ®µ**

```python
# éŸ³é »æ•¸æ“šé è™•ç†ç®¡é“
class AudioPreprocessingPipeline:
    def __init__(self, gpt_sovits_path):
        self.gpt_sovits_path = gpt_sovits_path
        self.tools_path = f"{gpt_sovits_path}/tools"

    def preprocess_audio_data(self, staff_code, raw_audio_files):
        """å®Œæ•´çš„éŸ³é »é è™•ç†ç®¡é“"""
        processed_data = []

        for audio_file in raw_audio_files:
            try:
                # 1. äººè²åˆ†é›¢ (ä½¿ç”¨ UVR5)
                vocal_file = self.separate_vocals(audio_file)

                # 2. éŸ³é »åˆ‡ç‰‡ (3-10ç§’ç‰‡æ®µ)
                segments = self.slice_audio(vocal_file)

                # 3. è‡ªå‹•èªéŸ³è­˜åˆ¥ (ASR)
                for segment in segments:
                    transcript = self.transcribe_audio(segment)

                    # 4. éŸ³é »å“è³ªæª¢æŸ¥
                    if self.validate_audio_quality(segment, transcript):
                        processed_data.append({
                            'audio_path': segment,
                            'transcript': transcript,
                            'speaker_id': staff_code,
                            'duration': self.get_duration(segment)
                        })

            except Exception as e:
                print(f"è™•ç†éŸ³é »å¤±æ•— {audio_file}: {e}")
                continue

        return processed_data
```

**3. æ¨¡å‹å¾®èª¿éšæ®µ**

```python
# GPT-SoVITS å¾®èª¿è¨“ç·´å™¨
class GPTSoVITSFineTuner:
    def __init__(self, gpt_sovits_path, staff_code):
        self.gpt_sovits_path = gpt_sovits_path
        self.staff_code = staff_code
        self.output_dir = f"models/{staff_code}"

        # å¾®èª¿é…ç½®
        self.config = {
            # GPT æ¨¡å‹é…ç½®
            'gpt_config': {
                'batch_size': 4,
                'learning_rate': 0.0001,
                'epochs': 15,
                'save_every_epoch': 5,
                'warmup_epoch': 2
            },
            # SoVITS æ¨¡å‹é…ç½®
            'sovits_config': {
                'batch_size': 8,
                'learning_rate': 0.0002,
                'epochs': 100,
                'save_every_epoch': 10,
                'total_epoch': 100
            }
        }

    def fine_tune_gpt_model(self, training_data):
        """å¾®èª¿ GPT æ¨¡å‹"""
        print("ğŸš€ é–‹å§‹ GPT æ¨¡å‹å¾®èª¿...")

        # 1. æº–å‚™è¨“ç·´åˆ—è¡¨
        train_list_path = self.prepare_gpt_train_list(training_data)

        # 2. åŸ·è¡Œ GPT å¾®èª¿
        cmd = [
            self.python_path,
            f"{self.gpt_sovits_path}/GPT_SoVITS/s1_train.py",
            "--config_path", f"{self.gpt_sovits_path}/configs/s1longer.yaml",
            "--train_list", train_list_path,
            "--output_dir", f"{self.output_dir}/gpt",
            "--batch_size", str(self.config['gpt_config']['batch_size']),
            "--learning_rate", str(self.config['gpt_config']['learning_rate']),
            "--epochs", str(self.config['gpt_config']['epochs'])
        ]

        process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)

        # ç›£æ§è¨“ç·´é€²åº¦
        for line in process.stdout:
            print(f"GPT è¨“ç·´: {line.strip()}")

        process.wait()

        if process.returncode != 0:
            raise RuntimeError(f"GPT æ¨¡å‹å¾®èª¿å¤±æ•—: {process.stderr.read()}")

        return self.get_best_gpt_checkpoint()

    def fine_tune_sovits_model(self, training_data, gpt_model_path):
        """å¾®èª¿ SoVITS æ¨¡å‹"""
        print("ğŸš€ é–‹å§‹ SoVITS æ¨¡å‹å¾®èª¿...")

        # 1. æº–å‚™è¨“ç·´åˆ—è¡¨
        train_list_path = self.prepare_sovits_train_list(training_data)

        # 2. åŸ·è¡Œ SoVITS å¾®èª¿
        cmd = [
            self.python_path,
            f"{self.gpt_sovits_path}/GPT_SoVITS/s2_train.py",
            "--config_path", f"{self.gpt_sovits_path}/configs/s2.json",
            "--train_list", train_list_path,
            "--output_dir", f"{self.output_dir}/sovits",
            "--gpt_model", gpt_model_path,
            "--batch_size", str(self.config['sovits_config']['batch_size']),
            "--learning_rate", str(self.config['sovits_config']['learning_rate']),
            "--total_epoch", str(self.config['sovits_config']['total_epoch'])
        ]

        process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)

        # ç›£æ§è¨“ç·´é€²åº¦
        for line in process.stdout:
            print(f"SoVITS è¨“ç·´: {line.strip()}")

        process.wait()

        if process.returncode != 0:
            raise RuntimeError(f"SoVITS æ¨¡å‹å¾®èª¿å¤±æ•—: {process.stderr.read()}")

        return self.get_best_sovits_checkpoint()
```

**4. æ¨ç†æœå‹™æ•´åˆ**

```python
# GPT-SoVITS æ¨ç†æœå‹™
class GPTSoVITSInferenceService:
    def __init__(self, gpt_sovits_path, staff_code):
        self.gpt_sovits_path = gpt_sovits_path
        self.staff_code = staff_code
        self.model_loaded = False

    def load_fine_tuned_model(self, gpt_model_path, sovits_model_path, reference_audio):
        """è¼‰å…¥å¾®èª¿å¾Œçš„æ¨¡å‹"""
        try:
            # å•Ÿå‹• GPT-SoVITS æ¨ç†æœå‹™
            self.inference_process = self.start_inference_server(
                gpt_model_path,
                sovits_model_path,
                reference_audio
            )

            # ç­‰å¾…æœå‹™å•Ÿå‹•
            time.sleep(10)

            # æ¸¬è©¦é€£æ¥
            if self.test_inference_connection():
                self.model_loaded = True
                print(f"âœ… {self.staff_code} æ¨¡å‹è¼‰å…¥æˆåŠŸ")
                return True
            else:
                raise RuntimeError("æ¨ç†æœå‹™é€£æ¥å¤±æ•—")

        except Exception as e:
            print(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
            return False

    def synthesize_speech(self, text, emotion="neutral", speed=1.0):
        """èªéŸ³åˆæˆ"""
        if not self.model_loaded:
            raise RuntimeError("æ¨¡å‹æœªè¼‰å…¥")

        # èª¿ç”¨ GPT-SoVITS API
        api_url = f"http://localhost:900{hash(self.staff_code) % 100}/synthesize"

        payload = {
            "text": text,
            "text_language": "zh",
            "ref_audio_path": self.reference_audio,
            "aux_ref_audio_paths": [],
            "prompt_text": "",
            "prompt_language": "zh",
            "top_k": 5,
            "top_p": 1.0,
            "temperature": 1.0,
            "text_split_method": "cut5",
            "batch_size": 1,
            "speed_factor": speed,
            "split_bucket": True,
            "return_fragment": False,
            "fragment_interval": 0.3
        }

        response = requests.post(api_url, json=payload, timeout=60)

        if response.status_code == 200:
            return response.content
        else:
            raise RuntimeError(f"èªéŸ³åˆæˆå¤±æ•—: {response.text}")
```

**5. å®Œæ•´å·¥ä½œæµç¨‹æ•´åˆ**

```python
# å®Œæ•´çš„ GPT-SoVITS å¾®èª¿å·¥ä½œæµç¨‹
class GPTSoVITSWorkflow:
    def __init__(self, staff_code, gpt_sovits_path="D:/python/GPT-SoVITS-v2pro-20250604"):
        self.staff_code = staff_code
        self.gpt_sovits_path = gpt_sovits_path
        self.workflow_status = "initialized"

    async def execute_full_workflow(self, raw_audio_files, reference_texts):
        """åŸ·è¡Œå®Œæ•´çš„å¾®èª¿å·¥ä½œæµç¨‹"""
        try:
            # 1. ç’°å¢ƒæº–å‚™
            self.workflow_status = "preparing_environment"
            env = GPTSoVITSEnvironment(self.gpt_sovits_path)
            env.setup_environment()

            # 2. æ•¸æ“šé è™•ç†
            self.workflow_status = "preprocessing_data"
            preprocessor = AudioPreprocessingPipeline(self.gpt_sovits_path)
            training_data = preprocessor.preprocess_audio_data(self.staff_code, raw_audio_files)

            if len(training_data) < 10:
                raise ValueError(f"è¨“ç·´æ•¸æ“šä¸è¶³ï¼Œéœ€è¦è‡³å°‘10å€‹æ¨£æœ¬ï¼Œç›®å‰åªæœ‰{len(training_data)}å€‹")

            # 3. GPT æ¨¡å‹å¾®èª¿
            self.workflow_status = "fine_tuning_gpt"
            fine_tuner = GPTSoVITSFineTuner(self.gpt_sovits_path, self.staff_code)
            gpt_model_path = fine_tuner.fine_tune_gpt_model(training_data)

            # 4. SoVITS æ¨¡å‹å¾®èª¿
            self.workflow_status = "fine_tuning_sovits"
            sovits_model_path = fine_tuner.fine_tune_sovits_model(training_data, gpt_model_path)

            # 5. æ¨¡å‹å“è³ªè©•ä¼°
            self.workflow_status = "evaluating_model"
            quality_metrics = self.evaluate_model_quality(
                gpt_model_path,
                sovits_model_path,
                training_data[:5]
            )

            # 6. éƒ¨ç½²æ¨ç†æœå‹™
            self.workflow_status = "deploying_model"
            if quality_metrics['overall_score'] > 0.7:
                inference_service = GPTSoVITSInferenceService(self.gpt_sovits_path, self.staff_code)
                reference_audio = training_data[0]['audio_path']

                success = inference_service.load_fine_tuned_model(
                    gpt_model_path,
                    sovits_model_path,
                    reference_audio
                )

                if success:
                    self.workflow_status = "completed"

                    # æ›´æ–°è³‡æ–™åº«è¨˜éŒ„
                    self.update_voice_model_record(
                        gpt_model_path,
                        sovits_model_path,
                        quality_metrics
                    )

                    return {
                        'status': 'success',
                        'gpt_model_path': gpt_model_path,
                        'sovits_model_path': sovits_model_path,
                        'quality_metrics': quality_metrics,
                        'inference_service': inference_service
                    }
                else:
                    raise RuntimeError("æ¨ç†æœå‹™éƒ¨ç½²å¤±æ•—")
            else:
                raise ValueError(f"æ¨¡å‹å“è³ªä¸é”æ¨™: {quality_metrics['overall_score']}")

        except Exception as e:
            self.workflow_status = "error"
            return {
                'status': 'error',
                'message': str(e),
                'workflow_status': self.workflow_status
            }
```

#### è³‡æ–™ä¸²æ¥æ¨¡å¼æ›´æ–°

```python
# å®Œæ•´çš„ GPT-SoVITS èªéŸ³åˆæˆæµç¨‹
"""
æ•¸æ“šæ”¶é›†éšæ®µ:
åŸå§‹éŸ³é » â†’ UVR5äººè²åˆ†é›¢ â†’ éŸ³é »åˆ‡ç‰‡ â†’ ASRè½‰éŒ„ â†’ å“è³ªæª¢æŸ¥ â†’ è¨“ç·´æ•¸æ“šé›†

æ¨¡å‹å¾®èª¿éšæ®µ:
è¨“ç·´æ•¸æ“š â†’ GPTæ¨¡å‹å¾®èª¿ â†’ SoVITSæ¨¡å‹å¾®èª¿ â†’ æ¨¡å‹é©—è­‰ â†’ å“è³ªè©•ä¼° â†’ æ¨¡å‹éƒ¨ç½²

èªéŸ³åˆæˆéšæ®µ:
æ–‡å­—è¼¸å…¥ â†’ GPTèªç¾©ç·¨ç¢¼ â†’ SoVITSè²å­¸åˆæˆ â†’ éŸ³é »å¾Œè™•ç† â†’ é«˜å“è³ªèªéŸ³è¼¸å‡º

æœå‹™éƒ¨ç½²éšæ®µ:
å¾®èª¿æ¨¡å‹ â†’ æ¨ç†æœå‹™å•Ÿå‹• â†’ APIæ¥å£æš´éœ² â†’ è² è¼‰å‡è¡¡ â†’ ç›£æ§å‘Šè­¦
"""
```

### 4. è³‡æ–™åº«ç®¡ç† (`database.py`)

#### è³‡æ–™åº«è¨­è¨ˆ

**æ ¸å¿ƒè³‡æ–™è¡¨**:

```sql
-- ç”¨æˆ¶è¡¨
users: id, username, email, password_hash, full_name, is_active, created_at

-- å®¢æœå°ˆå“¡è¡¨
staff: id, name, code, phone, email, status, description, created_at

-- éŸ³é »è¨˜éŒ„è¡¨
audio: id, name, staff_id, file_path, duration, file_size,
       emotion, emotion_confidence, emotion_analysis_data, created_at

-- æƒ…ç·’åˆ†æçµæœè¡¨
emotion_analysis: id, audio_id, method, predicted_emotion, confidence,
                  all_emotions_json, features_json, analyzed_at

-- èªéŸ³æ¨¡å‹è¡¨
voice_models: id, staff_code, original_audio_path, processed_audio_path,
              reference_text, model_status, quality_score, created_at
```

#### è³‡æ–™å­˜å–æ¨¡å¼

- **ORM æ¨¡å¼**: ä½¿ç”¨åŸç”Ÿ SQL + å­—å…¸æ˜ å°„
- **é€£æ¥æ± **: SQLite é€£æ¥ç®¡ç†
- **äº‹å‹™è™•ç†**: æ”¯æ´ ACID ç‰¹æ€§
- **åˆ†é æŸ¥è©¢**: é«˜æ•ˆèƒ½åˆ†é å¯¦ä½œ

## ğŸ” å®‰å…¨æ©Ÿåˆ¶

### èº«ä»½é©—è­‰

```python
# JWT Token é©—è­‰
app.config['JWT_SECRET_KEY'] = 'your-secret-key'
app.config['JWT_ACCESS_TOKEN_EXPIRES'] = timedelta(hours=8)

# å¯†ç¢¼åŠ å¯†
password_hash = bcrypt.hashpw(password.encode('utf-8'), bcrypt.gensalt())
```

### æª”æ¡ˆå®‰å…¨

```python
# æª”æ¡ˆåç¨±å®‰å…¨åŒ–
filename = secure_filename(f"{audio_id}_{file.filename}")

# æª”æ¡ˆé¡å‹é©—è­‰
ALLOWED_EXTENSIONS = {'wav', 'mp3', 'm4a', 'flac', 'ogg'}

# æª”æ¡ˆå¤§å°é™åˆ¶
app.config['MAX_CONTENT_LENGTH'] = 50 * 1024 * 1024  # 50MB
```

## ğŸ“Š æ•ˆèƒ½å„ªåŒ–

### éŸ³é »è™•ç†å„ªåŒ–

- **ç•°æ­¥è™•ç†**: æƒ…ç·’åˆ†æä¸é˜»å¡ä¸»æµç¨‹
- **æª”æ¡ˆå¿«å–**: è‡¨æ™‚æª”æ¡ˆè‡ªå‹•æ¸…ç†
- **è¨˜æ†¶é«”ç®¡ç†**: å¤§æª”æ¡ˆåˆ†å¡Šè™•ç†

### è³‡æ–™åº«å„ªåŒ–

- **ç´¢å¼•è¨­è¨ˆ**: é—œéµæ¬„ä½å»ºç«‹ç´¢å¼•
- **æŸ¥è©¢å„ªåŒ–**: åˆ†é æŸ¥è©¢å’Œæ¢ä»¶ç¯©é¸
- **é€£æ¥ç®¡ç†**: é©ç•¶çš„é€£æ¥æ± å¤§å°

## ğŸš€ æ¨¡å‹å„²å­˜èˆ‡éƒ¨ç½²æ¶æ§‹

### ğŸ“¦ æ¨¡å‹å„²å­˜ç­–ç•¥

#### 1. æœ¬åœ°ç«¯å„²å­˜æ¶æ§‹ (ç›®å‰å¯¦ä½œ)

**ç›®éŒ„çµæ§‹**:

```
project_root/
â”œâ”€â”€ models/                          # æ¨¡å‹å„²å­˜æ ¹ç›®éŒ„
â”‚   â”œâ”€â”€ pretrained/                  # é è¨“ç·´æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ emotion_recognition/     # æƒ…ç·’è­˜åˆ¥é è¨“ç·´æ¨¡å‹
â”‚   â”‚   â”‚   â”œâ”€â”€ wav2vec2_base.pt    # Wav2Vec2 åŸºç¤æ¨¡å‹
â”‚   â”‚   â”‚   â””â”€â”€ librosa_features.pkl # librosa ç‰¹å¾µæå–å™¨
â”‚   â”‚   â””â”€â”€ gpt_sovits/             # GPT-SoVITS é è¨“ç·´æ¨¡å‹
â”‚   â”‚       â”œâ”€â”€ s1bert25hz.ckpt     # GPT é è¨“ç·´æ¨¡å‹
â”‚   â”‚       â”œâ”€â”€ s2G488k.pth         # SoVITS G æ¨¡å‹
â”‚   â”‚       â””â”€â”€ s2D488k.pth         # SoVITS D æ¨¡å‹
â”‚   â”œâ”€â”€ fine_tuned/                 # å¾®èª¿æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ staff001/               # å®¢æœå°ˆå“¡ 001
â”‚   â”‚   â”‚   â”œâ”€â”€ gpt_model.pt        # å¾®èª¿å¾Œçš„ GPT æ¨¡å‹
â”‚   â”‚   â”‚   â”œâ”€â”€ sovits_model.pt     # å¾®èª¿å¾Œçš„ SoVITS æ¨¡å‹
â”‚   â”‚   â”‚   â”œâ”€â”€ speaker_embedding.pt # èªªè©±äººåµŒå…¥
â”‚   â”‚   â”‚   â”œâ”€â”€ model_config.json   # æ¨¡å‹é…ç½®
â”‚   â”‚   â”‚   â””â”€â”€ quality_metrics.json # å“è³ªæŒ‡æ¨™
â”‚   â”‚   â””â”€â”€ staff002/               # å®¢æœå°ˆå“¡ 002
â”‚   â”‚       â””â”€â”€ ...
â”‚   â”œâ”€â”€ cache/                      # æ¨¡å‹å¿«å–
â”‚   â”‚   â”œâ”€â”€ inference_cache/        # æ¨ç†å¿«å–
â”‚   â”‚   â””â”€â”€ feature_cache/          # ç‰¹å¾µå¿«å–
â”‚   â””â”€â”€ backups/                    # æ¨¡å‹å‚™ä»½
â”‚       â”œâ”€â”€ daily/                  # æ¯æ—¥å‚™ä»½
â”‚       â””â”€â”€ weekly/                 # æ¯é€±å‚™ä»½
```

**æœ¬åœ°ç«¯æ¨¡å‹ç®¡ç†å™¨**:

```python
class LocalModelManager:
    def __init__(self, base_path="./models"):
        self.base_path = base_path
        self.pretrained_path = f"{base_path}/pretrained"
        self.fine_tuned_path = f"{base_path}/fine_tuned"
        self.cache_path = f"{base_path}/cache"
        self.backup_path = f"{base_path}/backups"

    def save_fine_tuned_model(self, staff_code, model_data, quality_metrics):
        """å„²å­˜å¾®èª¿å¾Œçš„æ¨¡å‹"""
        model_dir = f"{self.fine_tuned_path}/{staff_code}"
        os.makedirs(model_dir, exist_ok=True)

        # å„²å­˜æ¨¡å‹æª”æ¡ˆ
        torch.save(model_data['gpt_model'], f"{model_dir}/gpt_model.pt")
        torch.save(model_data['sovits_model'], f"{model_dir}/sovits_model.pt")
        torch.save(model_data['speaker_embedding'], f"{model_dir}/speaker_embedding.pt")

        # å„²å­˜é…ç½®å’ŒæŒ‡æ¨™
        with open(f"{model_dir}/model_config.json", 'w') as f:
            json.dump(model_data['config'], f, indent=2)

        with open(f"{model_dir}/quality_metrics.json", 'w') as f:
            json.dump(quality_metrics, f, indent=2)

        # å‰µå»ºå‚™ä»½
        self.create_backup(staff_code)

        return model_dir

    def load_fine_tuned_model(self, staff_code):
        """è¼‰å…¥å¾®èª¿å¾Œçš„æ¨¡å‹"""
        model_dir = f"{self.fine_tuned_path}/{staff_code}"

        if not os.path.exists(model_dir):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ° {staff_code} çš„æ¨¡å‹")

        # è¼‰å…¥æ¨¡å‹
        gpt_model = torch.load(f"{model_dir}/gpt_model.pt")
        sovits_model = torch.load(f"{model_dir}/sovits_model.pt")
        speaker_embedding = torch.load(f"{model_dir}/speaker_embedding.pt")

        # è¼‰å…¥é…ç½®
        with open(f"{model_dir}/model_config.json", 'r') as f:
            config = json.load(f)

        return {
            'gpt_model': gpt_model,
            'sovits_model': sovits_model,
            'speaker_embedding': speaker_embedding,
            'config': config
        }

    def create_backup(self, staff_code):
        """å‰µå»ºæ¨¡å‹å‚™ä»½"""
        source_dir = f"{self.fine_tuned_path}/{staff_code}"
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_dir = f"{self.backup_path}/daily/{staff_code}_{timestamp}"

        shutil.copytree(source_dir, backup_dir)

        # æ¸…ç†èˆŠå‚™ä»½ï¼ˆä¿ç•™æœ€è¿‘ 7 å¤©ï¼‰
        self.cleanup_old_backups(staff_code, days=7)

    def get_model_info(self, staff_code):
        """ç²å–æ¨¡å‹è³‡è¨Š"""
        model_dir = f"{self.fine_tuned_path}/{staff_code}"

        if not os.path.exists(model_dir):
            return None

        # è®€å–å“è³ªæŒ‡æ¨™
        metrics_file = f"{model_dir}/quality_metrics.json"
        if os.path.exists(metrics_file):
            with open(metrics_file, 'r') as f:
                quality_metrics = json.load(f)
        else:
            quality_metrics = {}

        # ç²å–æª”æ¡ˆè³‡è¨Š
        model_files = os.listdir(model_dir)
        file_sizes = {
            file: os.path.getsize(os.path.join(model_dir, file))
            for file in model_files
        }

        return {
            'staff_code': staff_code,
            'model_path': model_dir,
            'quality_metrics': quality_metrics,
            'file_sizes': file_sizes,
            'last_modified': os.path.getmtime(model_dir),
            'total_size': sum(file_sizes.values())
        }
```

#### 2. GCP é›²ç«¯éƒ¨ç½²æ¶æ§‹ (æœªä¾†æ“´å±•)

**GCP æœå‹™æ¶æ§‹**:

```
Google Cloud Platform éƒ¨ç½²æ¶æ§‹
â”œâ”€â”€ Compute Engine                   # ä¸»è¦é‹ç®—è³‡æº
â”‚   â”œâ”€â”€ AI Training Instances        # æ¨¡å‹è¨“ç·´å°ˆç”¨å¯¦ä¾‹
â”‚   â”‚   â”œâ”€â”€ GPU: NVIDIA T4/V100     # GPU åŠ é€Ÿè¨“ç·´
â”‚   â”‚   â”œâ”€â”€ CPU: 8-16 vCPUs         # é«˜æ•ˆèƒ½ CPU
â”‚   â”‚   â””â”€â”€ RAM: 32-64 GB           # å¤§è¨˜æ†¶é«”æ”¯æ´
â”‚   â””â”€â”€ Inference Instances          # æ¨ç†æœå‹™å¯¦ä¾‹
â”‚       â”œâ”€â”€ GPU: NVIDIA T4          # æ¨ç†åŠ é€Ÿ
â”‚       â”œâ”€â”€ Auto Scaling Group      # è‡ªå‹•æ“´å±•
â”‚       â””â”€â”€ Load Balancer           # è² è¼‰å‡è¡¡
â”œâ”€â”€ Cloud Storage                    # æ¨¡å‹å’Œæ•¸æ“šå„²å­˜
â”‚   â”œâ”€â”€ Model Bucket                # æ¨¡å‹æª”æ¡ˆå„²å­˜
â”‚   â”‚   â”œâ”€â”€ pretrained-models/      # é è¨“ç·´æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ fine-tuned-models/      # å¾®èª¿æ¨¡å‹
â”‚   â”‚   â””â”€â”€ model-backups/          # æ¨¡å‹å‚™ä»½
â”‚   â”œâ”€â”€ Audio Bucket                # éŸ³é »æª”æ¡ˆå„²å­˜
â”‚   â”‚   â”œâ”€â”€ raw-audio/              # åŸå§‹éŸ³é »
â”‚   â”‚   â”œâ”€â”€ processed-audio/        # è™•ç†å¾ŒéŸ³é »
â”‚   â”‚   â””â”€â”€ generated-audio/        # ç”ŸæˆéŸ³é »
â”‚   â””â”€â”€ Training Data Bucket        # è¨“ç·´æ•¸æ“š
â”œâ”€â”€ Cloud SQL                       # é—œè¯å¼è³‡æ–™åº«
â”‚   â”œâ”€â”€ PostgreSQL Instance         # ä¸»è³‡æ–™åº«
â”‚   â”œâ”€â”€ Read Replicas              # è®€å–å‰¯æœ¬
â”‚   â””â”€â”€ Backup & Recovery          # å‚™ä»½æ¢å¾©
â”œâ”€â”€ Cloud Memorystore              # Redis å¿«å–
â”‚   â”œâ”€â”€ Model Cache                # æ¨¡å‹å¿«å–
â”‚   â”œâ”€â”€ Session Cache              # æœƒè©±å¿«å–
â”‚   â””â”€â”€ Feature Cache              # ç‰¹å¾µå¿«å–
â”œâ”€â”€ Cloud Run                      # å®¹å™¨åŒ–æœå‹™
â”‚   â”œâ”€â”€ API Gateway                # API é–˜é“
â”‚   â”œâ”€â”€ Authentication Service     # èº«ä»½é©—è­‰æœå‹™
â”‚   â””â”€â”€ Monitoring Service         # ç›£æ§æœå‹™
â”œâ”€â”€ AI Platform                    # æ©Ÿå™¨å­¸ç¿’å¹³å°
â”‚   â”œâ”€â”€ Training Jobs              # è¨“ç·´ä»»å‹™
â”‚   â”œâ”€â”€ Prediction Services        # é æ¸¬æœå‹™
â”‚   â””â”€â”€ Model Registry             # æ¨¡å‹è¨»å†Šè¡¨
â””â”€â”€ Cloud Functions                # ç„¡ä¼ºæœå™¨å‡½æ•¸
    â”œâ”€â”€ Model Deployment           # æ¨¡å‹éƒ¨ç½²å‡½æ•¸
    â”œâ”€â”€ Data Processing            # æ•¸æ“šè™•ç†å‡½æ•¸
    â””â”€â”€ Webhook Handlers           # Webhook è™•ç†
```

**GCP æ¨¡å‹ç®¡ç†å™¨**:

```python
from google.cloud import storage, aiplatform
from google.cloud.sql import connector
import redis

class GCPModelManager:
    def __init__(self, project_id, region="asia-east1"):
        self.project_id = project_id
        self.region = region
        self.storage_client = storage.Client()
        self.model_bucket = "ai-customer-service-models"
        self.audio_bucket = "ai-customer-service-audio"

        # åˆå§‹åŒ– AI Platform
        aiplatform.init(project=project_id, location=region)

        # Redis å¿«å–é€£æ¥
        self.redis_client = redis.Redis(
            host='redis-instance-ip',
            port=6379,
            decode_responses=True
        )

    def upload_model_to_gcs(self, staff_code, local_model_path):
        """ä¸Šå‚³æ¨¡å‹åˆ° Google Cloud Storage"""
        bucket = self.storage_client.bucket(self.model_bucket)

        # ä¸Šå‚³æ¨¡å‹æª”æ¡ˆ
        model_files = os.listdir(local_model_path)
        uploaded_files = []

        for file_name in model_files:
            local_file_path = os.path.join(local_model_path, file_name)
            gcs_path = f"fine-tuned-models/{staff_code}/{file_name}"

            blob = bucket.blob(gcs_path)
            blob.upload_from_filename(local_file_path)

            uploaded_files.append({
                'file_name': file_name,
                'gcs_path': gcs_path,
                'size': os.path.getsize(local_file_path)
            })

        # æ›´æ–°æ¨¡å‹è¨»å†Šè¡¨
        self.register_model_in_ai_platform(staff_code, uploaded_files)

        return uploaded_files

    def register_model_in_ai_platform(self, staff_code, model_files):
        """åœ¨ AI Platform è¨»å†Šæ¨¡å‹"""
        model_display_name = f"voice-clone-{staff_code}"

        # å‰µå»ºæ¨¡å‹
        model = aiplatform.Model.upload(
            display_name=model_display_name,
            artifact_uri=f"gs://{self.model_bucket}/fine-tuned-models/{staff_code}/",
            serving_container_image_uri="gcr.io/cloud-aiplatform/prediction/pytorch-gpu.1-9:latest",
            description=f"GPT-SoVITS voice cloning model for staff {staff_code}"
        )

        return model

    def deploy_model_endpoint(self, staff_code, machine_type="n1-standard-4"):
        """éƒ¨ç½²æ¨¡å‹ç«¯é»"""
        model_display_name = f"voice-clone-{staff_code}"
        endpoint_display_name = f"voice-clone-endpoint-{staff_code}"

        # ç²å–æ¨¡å‹
        models = aiplatform.Model.list(
            filter=f'display_name="{model_display_name}"'
        )

        if not models:
            raise ValueError(f"æ‰¾ä¸åˆ°æ¨¡å‹: {model_display_name}")

        model = models[0]

        # å‰µå»ºç«¯é»
        endpoint = aiplatform.Endpoint.create(
            display_name=endpoint_display_name
        )

        # éƒ¨ç½²æ¨¡å‹åˆ°ç«¯é»
        endpoint.deploy(
            model=model,
            deployed_model_display_name=f"deployed-{staff_code}",
            machine_type=machine_type,
            min_replica_count=1,
            max_replica_count=5,
            accelerator_type="NVIDIA_TESLA_T4",
            accelerator_count=1
        )

        return endpoint

    def setup_auto_scaling(self, staff_code):
        """è¨­ç½®è‡ªå‹•æ“´å±•"""
        endpoint_name = f"voice-clone-endpoint-{staff_code}"

        # é…ç½®è‡ªå‹•æ“´å±•ç­–ç•¥
        scaling_config = {
            "min_replica_count": 1,
            "max_replica_count": 10,
            "target_cpu_utilization": 70,
            "target_memory_utilization": 80
        }

        return scaling_config

    def setup_model_monitoring(self, staff_code):
        """è¨­ç½®æ¨¡å‹ç›£æ§"""
        monitoring_config = {
            "model_performance": {
                "latency_threshold": 2000,  # 2ç§’
                "error_rate_threshold": 0.05,  # 5%
                "throughput_threshold": 100  # æ¯åˆ†é˜ 100 è«‹æ±‚
            },
            "resource_usage": {
                "cpu_threshold": 80,  # 80%
                "memory_threshold": 85,  # 85%
                "gpu_threshold": 90  # 90%
            },
            "alerts": {
                "email": ["admin@company.com"],
                "slack_webhook": "https://hooks.slack.com/..."
            }
        }

        return monitoring_config
```

### ğŸ”„ æ¨¡å‹ç‰ˆæœ¬ç®¡ç†

#### ç‰ˆæœ¬æ§åˆ¶ç­–ç•¥

```python
class ModelVersionManager:
    def __init__(self, storage_backend="local"):  # "local" or "gcp"
        self.storage_backend = storage_backend
        self.version_format = "v{major}.{minor}.{patch}"

    def create_new_version(self, staff_code, model_data, quality_metrics):
        """å‰µå»ºæ–°çš„æ¨¡å‹ç‰ˆæœ¬"""
        # ç²å–ç•¶å‰æœ€æ–°ç‰ˆæœ¬
        current_version = self.get_latest_version(staff_code)

        # æ±ºå®šç‰ˆæœ¬è™Ÿå¢é‡ç­–ç•¥
        new_version = self.calculate_next_version(
            current_version,
            quality_metrics
        )

        # å„²å­˜æ–°ç‰ˆæœ¬
        version_path = self.save_versioned_model(
            staff_code,
            new_version,
            model_data,
            quality_metrics
        )

        # æ›´æ–°ç‰ˆæœ¬ç´¢å¼•
        self.update_version_index(staff_code, new_version, quality_metrics)

        return new_version, version_path

    def calculate_next_version(self, current_version, quality_metrics):
        """è¨ˆç®—ä¸‹ä¸€å€‹ç‰ˆæœ¬è™Ÿ"""
        if current_version is None:
            return "v1.0.0"

        major, minor, patch = self.parse_version(current_version)

        # æ ¹æ“šå“è³ªæŒ‡æ¨™æ±ºå®šç‰ˆæœ¬å¢é‡
        if quality_metrics.get('overall_score', 0) > 0.9:
            # é‡å¤§æ”¹é€²
            major += 1
            minor = 0
            patch = 0
        elif quality_metrics.get('overall_score', 0) > 0.8:
            # åŠŸèƒ½æ”¹é€²
            minor += 1
            patch = 0
        else:
            # å°å¹…æ”¹é€²
            patch += 1

        return f"v{major}.{minor}.{patch}"

    def rollback_to_version(self, staff_code, target_version):
        """å›æ»¾åˆ°æŒ‡å®šç‰ˆæœ¬"""
        version_path = self.get_version_path(staff_code, target_version)

        if not self.version_exists(staff_code, target_version):
            raise ValueError(f"ç‰ˆæœ¬ {target_version} ä¸å­˜åœ¨")

        # å‚™ä»½ç•¶å‰ç‰ˆæœ¬
        current_version = self.get_latest_version(staff_code)
        if current_version:
            self.backup_current_version(staff_code, current_version)

        # æ¢å¾©ç›®æ¨™ç‰ˆæœ¬
        self.restore_version(staff_code, target_version)

        return version_path
```

### ğŸš€ éƒ¨ç½²ç’°å¢ƒé…ç½®

#### æœ¬åœ°ç«¯éƒ¨ç½²

```bash
# é–‹ç™¼ç’°å¢ƒè¨­ç½®
# 1. ä¾è³´å®‰è£
pip install -r requirements.txt

# 2. æ¨¡å‹ç›®éŒ„åˆå§‹åŒ–
mkdir -p models/{pretrained,fine_tuned,cache,backups}

# 3. ä¸‹è¼‰é è¨“ç·´æ¨¡å‹
python scripts/download_pretrained_models.py

# 4. è³‡æ–™åº«åˆå§‹åŒ–
python -c "from database import init_db; init_db()"

# 5. å•Ÿå‹•æœå‹™
python app.py
```

#### GCP é›²ç«¯éƒ¨ç½²

```yaml
# docker-compose.gcp.yml
version: "3.8"
services:
  flask-app:
    build: .
    ports:
      - "8080:8080"
    environment:
      - FLASK_ENV=production
      - GOOGLE_CLOUD_PROJECT=${PROJECT_ID}
      - GOOGLE_APPLICATION_CREDENTIALS=/app/service-account.json
      - DATABASE_URL=postgresql://${DB_USER}:${DB_PASS}@${DB_HOST}:5432/${DB_NAME}
      - REDIS_URL=redis://${REDIS_HOST}:6379
      - MODEL_STORAGE_BACKEND=gcp
      - GCS_MODEL_BUCKET=${MODEL_BUCKET}
      - GCS_AUDIO_BUCKET=${AUDIO_BUCKET}
    volumes:
      - ./service-account.json:/app/service-account.json:ro
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: "2"
          memory: 4G
        reservations:
          cpus: "1"
          memory: 2G

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - flask-app
```

#### Kubernetes éƒ¨ç½²é…ç½®

```yaml
# k8s-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-customer-service
spec:
  replicas: 3
  selector:
    matchLabels:
      app: ai-customer-service
  template:
    metadata:
      labels:
        app: ai-customer-service
    spec:
      containers:
        - name: flask-app
          image: gcr.io/${PROJECT_ID}/ai-customer-service:latest
          ports:
            - containerPort: 8080
          env:
            - name: GOOGLE_CLOUD_PROJECT
              value: ${PROJECT_ID}
            - name: MODEL_STORAGE_BACKEND
              value: "gcp"
          resources:
            requests:
              memory: "2Gi"
              cpu: "1"
              nvidia.com/gpu: 1
            limits:
              memory: "4Gi"
              cpu: "2"
              nvidia.com/gpu: 1
          volumeMounts:
            - name: service-account
              mountPath: /app/service-account.json
              subPath: service-account.json
              readOnly: true
      volumes:
        - name: service-account
          secret:
            secretName: gcp-service-account

---
apiVersion: v1
kind: Service
metadata:
  name: ai-customer-service-service
spec:
  selector:
    app: ai-customer-service
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8080
  type: LoadBalancer
```

### ğŸ“Š æ•ˆèƒ½èˆ‡æˆæœ¬æ¯”è¼ƒ

#### æœ¬åœ°ç«¯ vs GCP æ¯”è¼ƒè¡¨

| é …ç›®         | æœ¬åœ°ç«¯éƒ¨ç½²   | GCP é›²ç«¯éƒ¨ç½² |
| ------------ | ------------ | ------------ |
| **åˆå§‹æˆæœ¬** | ç¡¬é«”æŠ•è³‡é«˜   | æŒ‰ä½¿ç”¨ä»˜è²»   |
| **ç¶­è­·æˆæœ¬** | äººåŠ›ç¶­è­·é«˜   | è¨—ç®¡æœå‹™ä½   |
| **æ“´å±•æ€§**   | ç¡¬é«”é™åˆ¶     | å½ˆæ€§æ“´å±•     |
| **å¯ç”¨æ€§**   | å–®é»æ•…éšœé¢¨éšª | 99.9% SLA    |
| **å®‰å…¨æ€§**   | è‡ªè¡Œç®¡ç†     | ä¼æ¥­ç´šå®‰å…¨   |
| **å‚™ä»½æ¢å¾©** | æ‰‹å‹•å‚™ä»½     | è‡ªå‹•å‚™ä»½     |
| **ç›£æ§å‘Šè­¦** | åŸºç¤ç›£æ§     | å®Œæ•´ç›£æ§     |
| **å¤šåœ°éƒ¨ç½²** | å›°é›£         | ç°¡å–®         |

#### æˆæœ¬ä¼°ç®— (æœˆè²»ç”¨)

**æœ¬åœ°ç«¯æˆæœ¬**:

- ç¡¬é«”æ”¤æ: $2,000-5,000
- é›»è²»: $200-500
- ç¶­è­·äººåŠ›: $3,000-8,000
- **ç¸½è¨ˆ**: $5,200-13,500/æœˆ

**GCP æˆæœ¬** (ä¸­ç­‰è² è¼‰):

- Compute Engine: $800-1,500
- Cloud Storage: $100-300
- Cloud SQL: $200-500
- AI Platform: $300-800
- ç¶²è·¯æµé‡: $100-200
- **ç¸½è¨ˆ**: $1,500-3,300/æœˆ

### ğŸ”§ é·ç§»ç­–ç•¥

#### å¾æœ¬åœ°ç«¯åˆ° GCP çš„é·ç§»æ­¥é©Ÿ

1. **è©•ä¼°éšæ®µ** (1-2 é€±)

   - åˆ†æç¾æœ‰æ¨¡å‹å’Œæ•¸æ“šé‡
   - è©•ä¼°ç¶²è·¯é »å¯¬éœ€æ±‚
   - åˆ¶å®šé·ç§»æ™‚ç¨‹è¡¨

2. **æº–å‚™éšæ®µ** (2-3 é€±)

   - è¨­ç½® GCP å°ˆæ¡ˆå’Œæœå‹™
   - é…ç½®ç¶²è·¯å’Œå®‰å…¨è¨­å®š
   - æº–å‚™é·ç§»è…³æœ¬

3. **æ¸¬è©¦éšæ®µ** (1-2 é€±)

   - å°è¦æ¨¡æ•¸æ“šé·ç§»æ¸¬è©¦
   - åŠŸèƒ½é©—è­‰æ¸¬è©¦
   - æ•ˆèƒ½åŸºæº–æ¸¬è©¦

4. **é·ç§»éšæ®µ** (1 é€±)

   - æ•¸æ“šæ‰¹é‡é·ç§»
   - æœå‹™åˆ‡æ›
   - ç›£æ§å’Œèª¿å„ª

5. **é©—è­‰éšæ®µ** (1 é€±)
   - å…¨åŠŸèƒ½æ¸¬è©¦
   - æ•ˆèƒ½é©—è­‰
   - ç”¨æˆ¶æ¥å—æ¸¬è©¦

é€™å€‹æ¨¡å‹å„²å­˜èˆ‡éƒ¨ç½²æ¶æ§‹æä¾›äº†å¾æœ¬åœ°ç«¯åˆ°é›²ç«¯çš„å®Œæ•´è§£æ±ºæ–¹æ¡ˆï¼Œç¢ºä¿ç³»çµ±èƒ½å¤ éš¨è‘—æ¥­å‹™éœ€æ±‚çš„å¢é•·è€Œå½ˆæ€§æ“´å±•ã€‚

## ğŸ”§ é…ç½®ç®¡ç†

### ç’°å¢ƒé…ç½® (`config.py`)

```python
# æª”æ¡ˆè·¯å¾‘é…ç½®
AUDIO_UPLOAD_FOLDER = 'audio_uploads'
VOICE_OUTPUT_FOLDER = 'voice_output'
DATABASE = 'customer_service.db'

# æ”¯æ´çš„æª”æ¡ˆæ ¼å¼
ALLOWED_EXTENSIONS = {'wav', 'mp3', 'm4a', 'flac', 'ogg'}

# API é…ç½®
API_TIMEOUT = 60  # ç§’
MAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB
```

## ğŸ“ˆ ç›£æ§èˆ‡æ—¥èªŒ

### æ—¥èªŒè¨˜éŒ„

```python
import logging

# è¨­å®šæ—¥èªŒç´šåˆ¥
logging.basicConfig(level=logging.INFO)

# é—œéµæ“ä½œè¨˜éŒ„
logger.info(f"éŸ³é »ä¸Šå‚³æˆåŠŸ: {audio_id}")
logger.error(f"æƒ…ç·’åˆ†æå¤±æ•—: {error}")
```

### æ•ˆèƒ½ç›£æ§

- **API å›æ‡‰æ™‚é–“**: è¨˜éŒ„å„ç«¯é»å›æ‡‰æ™‚é–“
- **æª”æ¡ˆè™•ç†æ™‚é–“**: ç›£æ§éŸ³é »è™•ç†æ•ˆèƒ½
- **éŒ¯èª¤ç‡çµ±è¨ˆ**: è¿½è¹¤ç³»çµ±ç©©å®šæ€§

## ğŸ§ª æ¸¬è©¦ç­–ç•¥

### å–®å…ƒæ¸¬è©¦

```python
# æƒ…ç·’è­˜åˆ¥æ¸¬è©¦
def test_emotion_recognition():
    result = emotion_recognizer.predict_emotion('test_audio.wav')
    assert 'predicted_emotion' in result
    assert 'confidence' in result
```

### æ•´åˆæ¸¬è©¦

```python
# API ç«¯é»æ¸¬è©¦
def test_audio_upload():
    response = client.post('/api/audio/upload',
                          files={'file': test_audio_file})
    assert response.status_code == 201
```

## ğŸ”® æ“´å±•æ€§è€ƒé‡

### æ°´å¹³æ“´å±•

- **å¾®æœå‹™æ¶æ§‹**: å¯æ‹†åˆ†ç‚ºç¨ç«‹çš„æƒ…ç·’åˆ†ææœå‹™
- **è² è¼‰å‡è¡¡**: æ”¯æ´å¤šå¯¦ä¾‹éƒ¨ç½²
- **å¿«å–å±¤**: Redis å¿«å–ç†±é–€è³‡æ–™

### åŠŸèƒ½æ“´å±•

- **å¤šèªè¨€æ”¯æ´**: æ”¯æ´å¤šç¨®èªè¨€çš„æƒ…ç·’è­˜åˆ¥
- **å³æ™‚è™•ç†**: WebSocket æ”¯æ´å³æ™‚éŸ³é »åˆ†æ
- **AI æ¨¡å‹æ›´æ–°**: æ”¯æ´æ¨¡å‹ç†±æ›´æ–°æ©Ÿåˆ¶

## ğŸ“š é‡è¦æŠ€è¡“æ±ºç­–

1. **SQLite vs PostgreSQL**: é–‹ç™¼éšæ®µä½¿ç”¨ SQLiteï¼Œç”Ÿç”¢ç’°å¢ƒå»ºè­° PostgreSQL
2. **åŒæ­¥ vs ç•°æ­¥**: æƒ…ç·’åˆ†ææ¡ç”¨ç•°æ­¥è™•ç†ï¼Œä¸å½±éŸ¿ä¸»æµç¨‹
3. **æœ¬åœ° vs é›²ç«¯**: åŸºç¤æƒ…ç·’è­˜åˆ¥æœ¬åœ°è™•ç†ï¼Œé€²éšç‰ˆæœ¬å¯è€ƒæ…®é›²ç«¯ API
4. **æª”æ¡ˆå„²å­˜**: æœ¬åœ°æª”æ¡ˆç³»çµ±ï¼Œå¯æ“´å±•è‡³é›²ç«¯å„²å­˜ (AWS S3, Azure Blob)

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

1. **éŸ³é »æ ¼å¼ä¸æ”¯æ´**: æª¢æŸ¥ `ALLOWED_EXTENSIONS` è¨­å®š
2. **æƒ…ç·’è­˜åˆ¥å¤±æ•—**: æª¢æŸ¥ librosa å’Œç›¸é—œä¾è³´
3. **æª”æ¡ˆä¸Šå‚³å¤±æ•—**: æª¢æŸ¥æª”æ¡ˆå¤§å°å’Œæ¬Šé™è¨­å®š
4. **è³‡æ–™åº«é€£æ¥éŒ¯èª¤**: æª¢æŸ¥è³‡æ–™åº«æª”æ¡ˆæ¬Šé™å’Œè·¯å¾‘

### é™¤éŒ¯å·¥å…·

```python
# é–‹å•Ÿé™¤éŒ¯æ¨¡å¼
app.run(debug=True)

# è©³ç´°éŒ¯èª¤æ—¥èªŒ
import traceback
traceback.print_exc()
```

é€™ä»½æ–‡ä»¶æ¶µè“‹äº†å¾Œç«¯ç³»çµ±çš„æ ¸å¿ƒæŠ€è¡“æ¶æ§‹ã€æ¼”ç®—æ³•å¯¦ä½œã€è³‡æ–™ä¸²æ¥æ¨¡å¼ä»¥åŠé‡è¦çš„æŠ€è¡“æ±ºç­–ï¼Œç‚ºç³»çµ±çš„ç¶­è­·å’Œæ“´å±•æä¾›äº†å®Œæ•´çš„æŠ€è¡“æŒ‡å—ã€‚
