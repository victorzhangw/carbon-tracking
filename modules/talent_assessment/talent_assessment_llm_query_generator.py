"""
äººæ‰è©•é‘‘ç³»çµ± LLM SQL æŸ¥è©¢ç”Ÿæˆå™¨
ä½¿ç”¨ LLM ç†è§£ä½¿ç”¨è€…æ„åœ–ä¸¦ç”Ÿæˆå°æ‡‰çš„ SQL æŸ¥è©¢
"""

import json
import re
from typing import Dict, List, Optional, Tuple
from openai import OpenAI
from modules.talent_assessment.talent_assessment_query_validator import TalentAssessmentQueryValidator


class TalentAssessmentLLMQueryGenerator:
    """ä½¿ç”¨ LLM ç”Ÿæˆ SQL æŸ¥è©¢çš„é¡åˆ¥"""
    
    def __init__(self, api_key: str, base_url: str = None, model: str = "deepseek-ai/DeepSeek-V3"):
        """
        åˆå§‹åŒ– LLM æŸ¥è©¢ç”Ÿæˆå™¨
        
        Args:
            api_key: API é‡‘é‘°
            base_url: API åŸºç¤ URLï¼ˆå¯é¸ï¼‰
            model: ä½¿ç”¨çš„æ¨¡å‹åç¨±
        """
        self.client = OpenAI(api_key=api_key, base_url=base_url) if base_url else OpenAI(api_key=api_key)
        self.model = model
        self.validator = TalentAssessmentQueryValidator()
        
        # å»ºç«‹è³‡æ–™åº«çµæ§‹çš„æè¿°
        self.db_schema_description = self._build_schema_description()
    
    def _build_schema_description(self) -> str:
        """å»ºç«‹è³‡æ–™åº«çµæ§‹çš„æ–‡å­—æè¿°"""
        schema_desc = "# äººæ‰è©•é‘‘ç³»çµ±è³‡æ–™åº«çµæ§‹\n\n"
        
        tables = self.validator.get_all_tables()
        
        for table_name, table_info in tables.items():
            schema_desc += f"## è¡¨æ ¼: {table_name}\n"
            schema_desc += f"æ¬„ä½: {', '.join(table_info['columns'])}\n"
            schema_desc += f"ä¸»éµ: {table_info['primary_key']}\n"
            
            if 'foreign_keys' in table_info:
                schema_desc += "å¤–éµé—œè¯:\n"
                for fk_col, ref in table_info['foreign_keys'].items():
                    schema_desc += f"  - {fk_col} -> {ref}\n"
            
            schema_desc += "\n"
        
        return schema_desc
    
    def generate_sql_from_intent(self, user_intent: str, context: Dict = None) -> Dict:
        """
        æ ¹æ“šä½¿ç”¨è€…æ„åœ–ç”Ÿæˆ SQL æŸ¥è©¢
        
        Args:
            user_intent: ä½¿ç”¨è€…çš„æŸ¥è©¢æ„åœ–ï¼ˆè‡ªç„¶èªè¨€ï¼‰
            context: é¡å¤–çš„ä¸Šä¸‹æ–‡è³‡è¨Šï¼ˆå¦‚å·²çŸ¥çš„åƒæ•¸å€¼ï¼‰
        
        Returns:
            åŒ…å«ç”Ÿæˆçš„ SQLã€åƒæ•¸ã€èªªæ˜ç­‰è³‡è¨Šçš„å­—å…¸
        """
        # å…ˆæª¢æŸ¥æ˜¯å¦æœ‰é å®šç¾©çš„æ¨¡æ¿å¯ä»¥ä½¿ç”¨
        suggestions = self.validator.suggest_query_for_intent(user_intent)
        
        # å»ºç«‹ LLM æç¤º
        system_prompt = f"""ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ SQL æŸ¥è©¢ç”ŸæˆåŠ©æ‰‹ï¼Œå°ˆé–€ç‚ºäººæ‰è©•é‘‘ç³»çµ±ç”Ÿæˆ PostgreSQL æŸ¥è©¢ã€‚

{self.db_schema_description}

## é‡è¦è¦å‰‡ï¼š
1. åªç”Ÿæˆ SELECT æŸ¥è©¢ï¼Œä¸å…è¨± INSERTã€UPDATEã€DELETEã€DROP ç­‰æ“ä½œ
2. ä½¿ç”¨ PostgreSQL èªæ³•
3. ä½¿ç”¨åƒæ•¸åŒ–æŸ¥è©¢ï¼Œåƒæ•¸ç”¨ %s è¡¨ç¤º
4. JOIN æ™‚å¿…é ˆä½¿ç”¨æ­£ç¢ºçš„å¤–éµé—œè¯
5. ä¸­æ–‡æ¬„ä½åˆ¥åä½¿ç”¨ AS é—œéµå­—
6. ä½¿ç”¨ STRING_AGG è€Œä¸æ˜¯ GROUP_CONCATï¼ˆPostgreSQL èªæ³•ï¼‰
7. ç¢ºä¿æ‰€æœ‰è¡¨æ ¼å’Œæ¬„ä½åç¨±éƒ½å­˜åœ¨æ–¼è³‡æ–™åº«çµæ§‹ä¸­

## è¼¸å‡ºæ ¼å¼ï¼š
è«‹ä»¥ JSON æ ¼å¼å›æ‡‰ï¼ŒåŒ…å«ä»¥ä¸‹æ¬„ä½ï¼š
{{
    "sql": "ç”Ÿæˆçš„ SQL æŸ¥è©¢",
    "params": ["åƒæ•¸åˆ—è¡¨"],
    "param_descriptions": {{"param1": "åƒæ•¸1çš„æè¿°"}},
    "explanation": "æŸ¥è©¢çš„èªªæ˜",
    "tables_used": ["ä½¿ç”¨çš„è¡¨æ ¼åˆ—è¡¨"]
}}
"""
        
        user_prompt = f"""ä½¿ç”¨è€…æŸ¥è©¢æ„åœ–ï¼š{user_intent}

"""
        
        if context:
            user_prompt += f"å·²çŸ¥ä¸Šä¸‹æ–‡è³‡è¨Šï¼š{json.dumps(context, ensure_ascii=False)}\n\n"
        
        if suggestions:
            user_prompt += "åƒè€ƒæŸ¥è©¢æ¨¡æ¿ï¼š\n"
            for i, suggestion in enumerate(suggestions, 1):
                user_prompt += f"\næ¨¡æ¿ {i}: {suggestion['description']}\n"
                user_prompt += f"```sql\n{suggestion['query']}\n```\n"
        
        user_prompt += "\nè«‹æ ¹æ“šä½¿ç”¨è€…æ„åœ–ç”Ÿæˆå°æ‡‰çš„ SQL æŸ¥è©¢ã€‚"
        
        try:
            # å‘¼å« LLM
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.1,  # é™ä½æº«åº¦ä»¥ç²å¾—æ›´ç¢ºå®šçš„çµæœ
                max_tokens=2000
            )
            
            # è§£æå›æ‡‰
            content = response.choices[0].message.content
            
            # å˜—è©¦æå– JSON
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                result = json.loads(json_match.group())
            else:
                # å¦‚æœæ²’æœ‰æ‰¾åˆ° JSONï¼Œå˜—è©¦æå– SQL
                sql_match = re.search(r'```sql\n(.*?)\n```', content, re.DOTALL)
                if sql_match:
                    result = {
                        "sql": sql_match.group(1).strip(),
                        "params": [],
                        "param_descriptions": {},
                        "explanation": "LLM ç”Ÿæˆçš„æŸ¥è©¢",
                        "tables_used": []
                    }
                else:
                    raise ValueError("ç„¡æ³•å¾ LLM å›æ‡‰ä¸­æå– SQL æŸ¥è©¢")
            
            # é©—è­‰ç”Ÿæˆçš„ SQL
            is_valid, errors = self.validator.validate_query(result['sql'])
            
            result['is_valid'] = is_valid
            result['validation_errors'] = errors
            
            if not is_valid:
                result['warning'] = "ç”Ÿæˆçš„æŸ¥è©¢æœªé€šéé©—è­‰ï¼Œè«‹æª¢æŸ¥éŒ¯èª¤è¨Šæ¯"
            
            return result
            
        except Exception as e:
            return {
                "error": str(e),
                "sql": None,
                "is_valid": False
            }
    
    def explain_query(self, sql_query: str) -> str:
        """
        ä½¿ç”¨ LLM è§£é‡‹ SQL æŸ¥è©¢çš„å«ç¾©
        
        Args:
            sql_query: è¦è§£é‡‹çš„ SQL æŸ¥è©¢
        
        Returns:
            æŸ¥è©¢çš„è‡ªç„¶èªè¨€è§£é‡‹
        """
        system_prompt = """ä½ æ˜¯ä¸€å€‹ SQL æŸ¥è©¢è§£é‡‹å°ˆå®¶ã€‚è«‹ç”¨æ¸…æ™°ã€æ˜“æ‡‚çš„ä¸­æ–‡è§£é‡‹ SQL æŸ¥è©¢çš„å«ç¾©ã€‚

è§£é‡‹æ‡‰åŒ…å«ï¼š
1. æŸ¥è©¢çš„ç›®çš„
2. æ¶‰åŠçš„è¡¨æ ¼å’Œé—œè¯
3. ç¯©é¸æ¢ä»¶
4. è¿”å›çš„è³‡æ–™å…§å®¹
"""
        
        user_prompt = f"è«‹è§£é‡‹ä»¥ä¸‹ SQL æŸ¥è©¢ï¼š\n\n```sql\n{sql_query}\n```"
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3,
                max_tokens=1000
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            return f"è§£é‡‹æŸ¥è©¢æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}"
    
    def optimize_query(self, sql_query: str) -> Dict:
        """
        ä½¿ç”¨ LLM å„ªåŒ– SQL æŸ¥è©¢
        
        Args:
            sql_query: è¦å„ªåŒ–çš„ SQL æŸ¥è©¢
        
        Returns:
            åŒ…å«å„ªåŒ–å»ºè­°çš„å­—å…¸
        """
        system_prompt = f"""ä½ æ˜¯ä¸€å€‹ PostgreSQL æŸ¥è©¢å„ªåŒ–å°ˆå®¶ã€‚è«‹åˆ†æä¸¦å„ªåŒ–çµ¦å®šçš„ SQL æŸ¥è©¢ã€‚

{self.db_schema_description}

è«‹æä¾›ï¼š
1. å„ªåŒ–å¾Œçš„ SQL æŸ¥è©¢
2. å„ªåŒ–çš„ç†ç”±
3. æ•ˆèƒ½æ”¹é€²å»ºè­°
4. ç´¢å¼•å»ºè­°

ä»¥ JSON æ ¼å¼å›æ‡‰ï¼š
{{
    "optimized_sql": "å„ªåŒ–å¾Œçš„ SQL",
    "improvements": ["æ”¹é€²é»åˆ—è¡¨"],
    "index_suggestions": ["ç´¢å¼•å»ºè­°"],
    "explanation": "å„ªåŒ–èªªæ˜"
}}
"""
        
        user_prompt = f"è«‹å„ªåŒ–ä»¥ä¸‹ SQL æŸ¥è©¢ï¼š\n\n```sql\n{sql_query}\n```"
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.1,
                max_tokens=2000
            )
            
            content = response.choices[0].message.content
            
            # å˜—è©¦æå– JSON
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
            else:
                return {
                    "error": "ç„¡æ³•è§£æå„ªåŒ–å»ºè­°",
                    "raw_response": content
                }
            
        except Exception as e:
            return {
                "error": str(e)
            }


# ä½¿ç”¨ç¯„ä¾‹
if __name__ == "__main__":
    # æ³¨æ„ï¼šéœ€è¦è¨­å®šä½ çš„ API é‡‘é‘°
    API_KEY = "your-api-key-here"
    BASE_URL = "https://api.siliconflow.cn"
    
    generator = TalentAssessmentLLMQueryGenerator(
        api_key=API_KEY,
        base_url=BASE_URL
    )
    
    print("=== äººæ‰è©•é‘‘ç³»çµ± LLM SQL æŸ¥è©¢ç”Ÿæˆå™¨ ===\n")
    
    # æ¸¬è©¦æ¡ˆä¾‹
    test_intents = [
        "æŸ¥è©¢ Howard çš„æ‰€æœ‰ç‰¹è³ªåˆ†æ•¸",
        "æ‰¾å‡ºå“æ ¼èª ä¿¡ç´ é¤Šåˆ†æ•¸æœ€é«˜çš„å‰ 10 åå—æ¸¬è€…",
        "æŸ¥è©¢æ‰€æœ‰åŒç†å¿ƒåˆ†æ•¸ä½æ–¼ 50 çš„å—æ¸¬è€…",
        "é¡¯ç¤ºå°ˆæ¡ˆç¶“ç†è·ä½çš„å—æ¸¬è€…çš„å‘åº¦åˆ†æ•¸åˆ†å¸ƒ",
        "æŸ¥è©¢ 2025 å¹´ 9 æœˆå®Œæˆè©•é‘‘çš„æ‰€æœ‰å—æ¸¬è€…"
    ]
    
    for i, intent in enumerate(test_intents, 1):
        print(f"\n{'='*60}")
        print(f"æ¸¬è©¦ {i}: {intent}")
        print('='*60)
        
        result = generator.generate_sql_from_intent(intent)
        
        if 'error' in result:
            print(f"âŒ éŒ¯èª¤: {result['error']}")
        else:
            print(f"\nâœ… ç”Ÿæˆçš„ SQL:")
            print(result['sql'])
            
            if result.get('params'):
                print(f"\nğŸ“ åƒæ•¸: {result['params']}")
            
            if result.get('explanation'):
                print(f"\nğŸ’¡ èªªæ˜: {result['explanation']}")
            
            if not result['is_valid']:
                print(f"\nâš ï¸  é©—è­‰éŒ¯èª¤:")
                for error in result['validation_errors']:
                    print(f"  - {error}")
