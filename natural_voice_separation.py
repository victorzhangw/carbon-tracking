#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªç„¶éŸ³é »äººè²åˆ†é›¢å·¥å…·
ä¿æŒäººè²è‡ªç„¶åº¦ï¼Œé¿å…éŸ³èª¿è®ŠåŒ–å’Œä¸é€£çºŒå•é¡Œ
"""

import os
import sys
import librosa
import soundfile as sf
import numpy as np
from scipy import signal
from scipy.cluster.hierarchy import dendrogram, linkage, fcluster
from scipy.spatial.distance import pdist
import noisereduce as nr
from pydub import AudioSegment
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import argparse
from pathlib import Path

class NaturalVoiceSeparator:
    def __init__(self, input_file):
        self.input_file = input_file
        self.output_dir = Path(input_file).parent / "natural_separated_audio"
        self.output_dir.mkdir(exist_ok=True)
        
    def convert_to_wav(self):
        """å°‡ m4a æˆ–å…¶ä»–æ ¼å¼è½‰æ›ç‚º wavï¼Œä¿æŒåŸå§‹å“è³ª"""
        try:
            audio = AudioSegment.from_file(self.input_file)
            # ä¿æŒåŸå§‹æ¡æ¨£ç‡ï¼Œä¸å¼·åˆ¶æå‡
            wav_path = self.output_dir / f"{Path(self.input_file).stem}_converted.wav"
            audio.export(wav_path, format="wav")
            print(f"âœ“ éŸ³é »å·²è½‰æ›ç‚º WAV æ ¼å¼: {wav_path}")
            return str(wav_path)
        except Exception as e:
            print(f"âœ— è½‰æ›å¤±æ•—: {e}")
            return None
    
    def load_audio(self, file_path):
        """è¼‰å…¥éŸ³é »æª”æ¡ˆï¼Œä¿æŒåŸå§‹æ¡æ¨£ç‡"""
        try:
            y, sr = librosa.load(file_path, sr=None)
            print(f"âœ“ éŸ³é »è¼‰å…¥æˆåŠŸ - æ¡æ¨£ç‡: {sr}Hz, é•·åº¦: {len(y)/sr:.2f}ç§’")
            return y, sr
        except Exception as e:
            print(f"âœ— éŸ³é »è¼‰å…¥å¤±æ•—: {e}")
            return None, None
    
    def gentle_targeted_noise_reduction(self, y, sr):
        """æº«å’Œä¸”æœ‰é‡å°æ€§çš„å™ªéŸ³æ¸›å°‘ï¼Œä¿æŒäººè²è‡ªç„¶åº¦"""
        try:
            print("é–‹å§‹æº«å’Œçš„ç›®æ¨™å™ªéŸ³è™•ç†...")
            
            # 1. éå¸¸æº«å’Œçš„æ•´é«”å™ªéŸ³æ¸›å°‘
            y_stage1 = nr.reduce_noise(
                y=y, 
                sr=sr, 
                stationary=True, 
                prop_decrease=0.2,  # éå¸¸æº«å’Œ
                n_std_thresh_stationary=2.0,  # é«˜é–¾å€¼ï¼Œä¿è­·èªéŸ³
                n_fft=512  # è¼ƒå°çª—å£ï¼Œä¿æŒæ™‚é–“è§£æåº¦
            )
            
            # 2. åªé‡å°ç‰¹å®šé »ç‡çš„éˆ´è²é€²è¡Œè™•ç†
            y_no_ring = self.remove_specific_ring_tones(y_stage1, sr)
            
            # 3. ä¿æŒé€£çºŒæ€§çš„è¼•å¾®å¹³æ»‘
            y_smoothed = self.gentle_smoothing(y_no_ring, sr)
            
            print("âœ“ æº«å’Œå™ªéŸ³è™•ç†å®Œæˆ")
            return y_smoothed
            
        except Exception as e:
            print(f"âœ— å™ªéŸ³æ¸›å°‘å¤±æ•—: {e}")
            return y
    
    def remove_specific_ring_tones(self, y, sr):
        """åªå»é™¤ç‰¹å®šçš„éˆ´è²é »ç‡ï¼Œä¿æŒèªéŸ³å®Œæ•´"""
        try:
            nyquist = sr / 2
            y_filtered = y.copy()
            
            # åªé‡å°æœ€æ˜é¡¯çš„éˆ´è²é »ç‡ï¼Œä½¿ç”¨å¾ˆçª„çš„å¸¶é˜»æ¿¾æ³¢å™¨
            specific_ring_freqs = [
                (440, 460),   # æ¨™æº–éˆ´è² A4 é™„è¿‘
                (880, 900),   # é«˜é »éˆ´è²
            ]
            
            for low_freq, high_freq in specific_ring_freqs:
                if high_freq < nyquist:
                    # ä½¿ç”¨è¼ƒä½éšæ•¸çš„æ¿¾æ³¢å™¨ï¼Œæ¸›å°‘ç›¸ä½å¤±çœŸ
                    sos = signal.butter(2, [low_freq, high_freq], 
                                      btype='bandstop', fs=sr, output='sos')
                    y_filtered = signal.sosfilt(sos, y_filtered)
            
            print("âœ“ ç‰¹å®šéˆ´è²é »ç‡è™•ç†å®Œæˆ")
            return y_filtered
            
        except Exception as e:
            print(f"âœ— éˆ´è²è™•ç†å¤±æ•—: {e}")
            return y
    
    def gentle_smoothing(self, y, sr):
        """è¼•å¾®å¹³æ»‘è™•ç†ï¼Œä¿æŒè‡ªç„¶åº¦"""
        try:
            # ä½¿ç”¨å¾ˆå°çš„ç§»å‹•å¹³å‡çª—å£é€²è¡Œè¼•å¾®å¹³æ»‘
            window_size = int(sr * 0.001)  # 1ms çª—å£
            if window_size > 1:
                kernel = np.ones(window_size) / window_size
                y_smoothed = np.convolve(y, kernel, mode='same')
            else:
                y_smoothed = y
            
            # æ··åˆåŸå§‹ä¿¡è™Ÿå’Œå¹³æ»‘ä¿¡è™Ÿï¼Œä¿æŒè‡ªç„¶åº¦
            y_result = 0.9 * y + 0.1 * y_smoothed
            
            print("âœ“ è¼•å¾®å¹³æ»‘è™•ç†å®Œæˆ")
            return y_result
            
        except Exception as e:
            print(f"âœ— å¹³æ»‘è™•ç†å¤±æ•—: {e}")
            return y    

    def extract_voice_features_gentle(self, y, sr, frame_length=1024, hop_length=256):
        """æº«å’Œçš„èªéŸ³ç‰¹å¾µæå–ï¼Œä½¿ç”¨è¼ƒå°çš„çª—å£ä¿æŒé€£çºŒæ€§"""
        try:
            # ä½¿ç”¨è¼ƒå°çš„çª—å£å’Œè·³èºé•·åº¦ï¼Œä¿æŒæ™‚é–“é€£çºŒæ€§
            mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, 
                                       n_fft=frame_length, hop_length=hop_length)
            
            # åŸºé »æå–ï¼Œä½¿ç”¨è¼ƒå¯¬é¬†çš„åƒæ•¸
            f0, voiced_flag, voiced_probs = librosa.pyin(y, 
                                                       fmin=librosa.note_to_hz('C2'), 
                                                       fmax=librosa.note_to_hz('C7'),
                                                       frame_length=frame_length)
            
            # å…¶ä»–ç‰¹å¾µ
            spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr, 
                                                                 hop_length=hop_length)[0]
            zcr = librosa.feature.zero_crossing_rate(y, frame_length=frame_length, 
                                                   hop_length=hop_length)[0]
            
            print("âœ“ æº«å’ŒèªéŸ³ç‰¹å¾µæå–å®Œæˆ")
            return {
                'mfccs': mfccs,
                'f0': f0,
                'voiced_flag': voiced_flag,
                'spectral_centroids': spectral_centroids,
                'zcr': zcr
            }
            
        except Exception as e:
            print(f"âœ— ç‰¹å¾µæå–å¤±æ•—: {e}")
            return None
    
    def detect_voice_activity_conservative(self, y, sr, frame_length=1024, hop_length=256):
        """ä¿å®ˆçš„èªéŸ³æ´»å‹•æª¢æ¸¬ï¼Œé¿å…éåº¦åˆ‡å‰²"""
        try:
            # åˆ†å¹€
            frames = librosa.util.frame(y, frame_length=frame_length, 
                                      hop_length=hop_length)
            
            # è¨ˆç®—æ¯å¹€çš„èƒ½é‡
            energy = np.sum(frames ** 2, axis=0)
            
            # ä½¿ç”¨è¼ƒä½çš„é–¾å€¼ï¼Œä¿ç•™æ›´å¤šèªéŸ³
            energy_threshold = np.percentile(energy, 15)  # é™ä½åˆ°15%åˆ†ä½æ•¸
            
            # æª¢æ¸¬èªéŸ³æ´»å‹•
            voice_activity = energy > energy_threshold
            
            # æ›´å¼·çš„å¹³æ»‘è™•ç†ï¼Œé¿å…ä¸é€£çºŒ
            kernel = np.ones(15) / 15  # å¢åŠ å¹³æ»‘çª—å£
            voice_activity_smooth = np.convolve(voice_activity.astype(float), kernel, mode='same') > 0.3
            
            print("âœ“ ä¿å®ˆèªéŸ³æ´»å‹•æª¢æ¸¬å®Œæˆ")
            return voice_activity_smooth, energy
            
        except Exception as e:
            print(f"âœ— èªéŸ³æ´»å‹•æª¢æ¸¬å¤±æ•—: {e}")
            return None, None
    
    def separate_speakers_gentle(self, y, sr, n_speakers=2):
        """æº«å’Œçš„èªªè©±è€…åˆ†é›¢ï¼Œä¿æŒé€£çºŒæ€§"""
        try:
            print(f"é–‹å§‹æº«å’Œåˆ†é›¢ {n_speakers} å€‹èªªè©±è€…...")
            
            # ä½¿ç”¨è¼ƒå°çš„çª—å£åƒæ•¸
            frame_length = 1024
            hop_length = 256
            
            # ä¿å®ˆçš„èªéŸ³æ´»å‹•æª¢æ¸¬
            voice_activity, energy = self.detect_voice_activity_conservative(y, sr, frame_length, hop_length)
            if voice_activity is None:
                return None
            
            # æº«å’Œçš„ç‰¹å¾µæå–
            features = self.extract_voice_features_gentle(y, sr, frame_length, hop_length)
            if features is None:
                return None
            
            # æº–å‚™èšé¡ç‰¹å¾µï¼Œåªä½¿ç”¨æœ€ç©©å®šçš„ç‰¹å¾µ
            feature_matrix = []
            valid_indices = []
            
            for i in range(len(voice_activity)):
                if voice_activity[i] and i < features['mfccs'].shape[1]:
                    frame_features = []
                    
                    # åªä½¿ç”¨å‰8å€‹MFCCä¿‚æ•¸ï¼Œé¿å…éåº¦ç´°ç¯€
                    frame_features.extend(features['mfccs'][:8, i])
                    
                    # åŸºé »ç‰¹å¾µ (å¦‚æœæœ‰æ•ˆ)
                    if i < len(features['f0']) and not np.isnan(features['f0'][i]):
                        frame_features.append(features['f0'][i])
                    else:
                        frame_features.append(0)
                    
                    feature_matrix.append(frame_features)
                    valid_indices.append(i)
            
            if len(feature_matrix) < n_speakers:
                print("âœ— èªéŸ³å¹€æ•¸ä¸è¶³ä»¥é€²è¡Œèªªè©±è€…åˆ†é›¢")
                return None
            
            # æ¨™æº–åŒ–ç‰¹å¾µ
            feature_matrix = np.array(feature_matrix)
            scaler = StandardScaler()
            feature_matrix_scaled = scaler.fit_transform(feature_matrix)
            
            # K-means èšé¡ï¼Œä½¿ç”¨æ›´å¤šåˆå§‹åŒ–å˜—è©¦
            kmeans = KMeans(n_clusters=n_speakers, random_state=42, n_init=20)
            speaker_labels = kmeans.fit_predict(feature_matrix_scaled)
            
            print(f"âœ“ æº«å’Œèªªè©±è€…åˆ†é›¢å®Œæˆï¼Œè­˜åˆ¥å‡º {len(np.unique(speaker_labels))} å€‹èªªè©±è€…")
            
            return {
                'speaker_labels': speaker_labels,
                'valid_indices': valid_indices,
                'voice_activity': voice_activity,
                'hop_length': hop_length
            }
            
        except Exception as e:
            print(f"âœ— èªªè©±è€…åˆ†é›¢å¤±æ•—: {e}")
            return None
    
    def create_smooth_speaker_masks(self, y, sr, separation_result):
        """å‰µå»ºå¹³æ»‘çš„èªªè©±è€…é®ç½©ï¼Œé¿å…ä¸é€£çºŒ"""
        try:
            speaker_labels = separation_result['speaker_labels']
            valid_indices = separation_result['valid_indices']
            voice_activity = separation_result['voice_activity']
            hop_length = separation_result['hop_length']
            
            n_frames = len(voice_activity)
            n_speakers = len(np.unique(speaker_labels))
            
            # åˆå§‹åŒ–èªªè©±è€…é®ç½©
            speaker_masks = np.zeros((n_speakers, n_frames))
            
            # å¡«å……èªªè©±è€…æ¨™ç±¤
            label_idx = 0
            for frame_idx in range(n_frames):
                if voice_activity[frame_idx] and label_idx < len(speaker_labels):
                    speaker_id = speaker_labels[label_idx]
                    speaker_masks[speaker_id, frame_idx] = 1.0
                    label_idx += 1
            
            # å¼·åŠ›å¹³æ»‘é®ç½©ï¼Œé¿å…çªå…€åˆ‡æ›
            for speaker_id in range(n_speakers):
                # ä½¿ç”¨è¼ƒå¤§çš„å¹³æ»‘çª—å£
                kernel = np.ones(21) / 21  # å¢åŠ åˆ°21é»
                speaker_masks[speaker_id] = np.convolve(speaker_masks[speaker_id], kernel, mode='same')
                
                # æ‡‰ç”¨ sigmoid å‡½æ•¸ä½¿éæ¸¡æ›´å¹³æ»‘
                speaker_masks[speaker_id] = 1 / (1 + np.exp(-10 * (speaker_masks[speaker_id] - 0.5)))
            
            print(f"âœ“ å‰µå»ºäº† {n_speakers} å€‹å¹³æ»‘èªªè©±è€…é®ç½©")
            return speaker_masks, hop_length
            
        except Exception as e:
            print(f"âœ— å‰µå»ºèªªè©±è€…é®ç½©å¤±æ•—: {e}")
            return None, None
    
    def apply_gentle_speaker_separation(self, y, sr, speaker_masks, hop_length):
        """æº«å’Œæ‡‰ç”¨èªªè©±è€…åˆ†é›¢ï¼Œä¿æŒè‡ªç„¶åº¦"""
        try:
            # è¨ˆç®— STFTï¼Œä½¿ç”¨è¼ƒå°çš„çª—å£
            D = librosa.stft(y, hop_length=hop_length, n_fft=1024)
            magnitude, phase = np.abs(D), np.angle(D)
            
            separated_audios = []
            n_speakers = speaker_masks.shape[0]
            
            for speaker_id in range(n_speakers):
                # èª¿æ•´é®ç½©å¤§å°
                mask = speaker_masks[speaker_id]
                if len(mask) != magnitude.shape[1]:
                    mask = np.interp(np.linspace(0, len(mask)-1, magnitude.shape[1]), 
                                   np.arange(len(mask)), mask)
                
                # ç¢ºä¿é®ç½©ä¸æœƒå®Œå…¨ç‚º0ï¼Œä¿æŒä¸€äº›èƒŒæ™¯
                mask = np.maximum(mask, 0.1)  # æœ€å°ä¿ç•™10%
                
                # æ‡‰ç”¨é®ç½©
                masked_magnitude = magnitude * mask[np.newaxis, :]
                
                # é‡å»ºéŸ³é »
                masked_stft = masked_magnitude * np.exp(1j * phase)
                separated_audio = librosa.istft(masked_stft, hop_length=hop_length, length=len(y))
                
                separated_audios.append(separated_audio)
            
            print(f"âœ“ æº«å’Œåˆ†é›¢å‡º {len(separated_audios)} å€‹èªªè©±è€…çš„éŸ³é »")
            return separated_audios
            
        except Exception as e:
            print(f"âœ— éŸ³é »åˆ†é›¢å¤±æ•—: {e}")
            return None   
 
    def natural_speech_enhancement(self, y, sr):
        """è‡ªç„¶çš„èªéŸ³å¢å¼·ï¼Œé¿å…éŸ³èª¿è®ŠåŒ–"""
        try:
            # 1. éå¸¸è¼•å¾®çš„æ­£è¦åŒ–
            max_val = np.max(np.abs(y))
            if max_val > 0:
                y_normalized = y / max_val * 0.98  # è¼•å¾®æ­£è¦åŒ–
            else:
                y_normalized = y
            
            # 2. å»é™¤ç›´æµåç§»
            y_dc_removed = y_normalized - np.mean(y_normalized)
            
            # 3. éå¸¸è¼•å¾®çš„å‹•æ…‹ç¯„åœèª¿æ•´
            y_enhanced = np.sign(y_dc_removed) * np.power(np.abs(y_dc_removed), 0.95)
            
            print("âœ“ è‡ªç„¶èªéŸ³å¢å¼·å®Œæˆ")
            return y_enhanced
            
        except Exception as e:
            print(f"âœ— èªéŸ³å¢å¼·å¤±æ•—: {e}")
            return y
    
    def save_audio(self, audio_data, sr, filename):
        """å„²å­˜éŸ³é »æª”æ¡ˆ"""
        try:
            output_path = self.output_dir / filename
            sf.write(output_path, audio_data, sr)
            print(f"âœ“ éŸ³é »å·²å„²å­˜: {output_path}")
            return str(output_path)
        except Exception as e:
            print(f"âœ— éŸ³é »å„²å­˜å¤±æ•—: {e}")
            return None
    
    def process_audio(self, n_speakers=2):
        """ä¸»è¦è™•ç†æµç¨‹ - ä¿æŒè‡ªç„¶åº¦å„ªå…ˆ"""
        print(f"ğŸµ é–‹å§‹è‡ªç„¶éŸ³é »è™•ç† - åˆ†é›¢ {n_speakers} å€‹èªªè©±è€…")
        print("ğŸŒŸ å„ªå…ˆä¿æŒèªéŸ³è‡ªç„¶åº¦å’Œé€£çºŒæ€§")
        print("=" * 60)
        print(f"è™•ç†æª”æ¡ˆ: {self.input_file}")
        
        # 1. è½‰æ›æ ¼å¼
        wav_file = self.convert_to_wav()
        if not wav_file:
            return False
        
        # 2. è¼‰å…¥éŸ³é »
        y, sr = self.load_audio(wav_file)
        if y is None:
            return False
        
        # 3. æº«å’Œçš„ç›®æ¨™å™ªéŸ³æ¸›å°‘
        y_clean = self.gentle_targeted_noise_reduction(y, sr)
        
        # 4. è‡ªç„¶èªéŸ³å¢å¼·
        y_enhanced = self.natural_speech_enhancement(y_clean, sr)
        
        # 5. èªªè©±è€…åˆ†é›¢ï¼ˆå¯é¸ï¼‰
        separation_result = self.separate_speakers_gentle(y_enhanced, sr, n_speakers)
        
        # 6. å„²å­˜çµæœ
        results = {}
        results['original'] = self.save_audio(y, sr, "01_original.wav")
        results['noise_reduced'] = self.save_audio(y_clean, sr, "02_gentle_noise_reduced.wav")
        results['enhanced'] = self.save_audio(y_enhanced, sr, "03_naturally_enhanced.wav")
        
        if separation_result is not None:
            # å‰µå»ºå¹³æ»‘èªªè©±è€…é®ç½©
            speaker_masks, hop_length = self.create_smooth_speaker_masks(y_enhanced, sr, separation_result)
            if speaker_masks is not None:
                # æº«å’Œåˆ†é›¢èªªè©±è€…
                separated_audios = self.apply_gentle_speaker_separation(y_enhanced, sr, speaker_masks, hop_length)
                if separated_audios is not None:
                    # å„²å­˜åˆ†é›¢çš„èªªè©±è€…éŸ³é »
                    for i, speaker_audio in enumerate(separated_audios):
                        speaker_num = i + 1
                        # å°æ¯å€‹èªªè©±è€…æ‡‰ç”¨è‡ªç„¶å¢å¼·
                        speaker_enhanced = self.natural_speech_enhancement(speaker_audio, sr)
                        results[f'speaker_{speaker_num}'] = self.save_audio(
                            speaker_enhanced, sr, f"04_speaker_{speaker_num}_natural.wav"
                        )
        
        print("\n" + "=" * 60)
        print("ğŸ‰ è‡ªç„¶è™•ç†å®Œæˆï¼è¼¸å‡ºæª”æ¡ˆ:")
        for key, path in results.items():
            if path:
                print(f"  ğŸ“ {key}: {Path(path).name}")
        
        print(f"\nğŸ’¡ æ¨è–¦ä½¿ç”¨ (ä¿æŒè‡ªç„¶åº¦):")
        print(f"  ğŸ¯ æ•´é«”å¢å¼·: 03_naturally_enhanced.wav")
        if 'speaker_1' in results:
            print(f"  ğŸ¯ èªªè©±è€…1: 04_speaker_1_natural.wav")
        if 'speaker_2' in results:
            print(f"  ğŸ¯ èªªè©±è€…2: 04_speaker_2_natural.wav")
        
        print(f"\nğŸŒŸ ç‰¹é»: ä¿æŒåŸå§‹éŸ³èª¿å’Œé€£çºŒæ€§ï¼Œé¿å…äººå·¥æ„Ÿ")
        
        return True

def main():
    parser = argparse.ArgumentParser(description='è‡ªç„¶éŸ³é »äººè²åˆ†é›¢å·¥å…·')
    parser.add_argument('input_file', help='è¼¸å…¥éŸ³é »æª”æ¡ˆè·¯å¾‘')
    parser.add_argument('--speakers', type=int, default=2, help='èªªè©±è€…æ•¸é‡ (é è¨­: 2)')
    parser.add_argument('--output-dir', help='è¼¸å‡ºç›®éŒ„ (å¯é¸)')
    
    args = parser.parse_args()
    
    if not os.path.exists(args.input_file):
        print(f"âœ— æª”æ¡ˆä¸å­˜åœ¨: {args.input_file}")
        sys.exit(1)
    
    separator = NaturalVoiceSeparator(args.input_file)
    
    if args.output_dir:
        separator.output_dir = Path(args.output_dir)
        separator.output_dir.mkdir(exist_ok=True)
    
    success = separator.process_audio(n_speakers=args.speakers)
    
    if success:
        print("\nğŸ‰ è‡ªç„¶éŸ³é »è™•ç†æˆåŠŸå®Œæˆï¼")
    else:
        print("\nâŒ éŸ³é »è™•ç†å¤±æ•—")
        sys.exit(1)

if __name__ == "__main__":
    if len(sys.argv) == 1:
        input_file = r"D:\python\Flask-AICares\TTS\03041966.m4a"
        if os.path.exists(input_file):
            separator = NaturalVoiceSeparator(input_file)
            separator.process_audio(n_speakers=2)
        else:
            print(f"âœ— é è¨­æª”æ¡ˆä¸å­˜åœ¨: {input_file}")
            print("ä½¿ç”¨æ–¹æ³•: python natural_voice_separation.py <éŸ³é »æª”æ¡ˆè·¯å¾‘> [--speakers 2]")
    else:
        main()