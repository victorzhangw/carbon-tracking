import os
import json
from openai import OpenAI
from config import DEEPSEEK_API_KEY, BASE_URL, MODEL_NAME
from utils import fix_incomplete_json
from services.gpt_sovits_service import gpt_sovits_service
from database import save_voice_generation_record

# åˆå§‹åŒ–  AI å®¢æˆ¶ç«¯
client = OpenAI(
    api_key=DEEPSEEK_API_KEY,
    base_url=BASE_URL,
)

def analyze_and_respond(transcript):
    """åˆ†ææ–‡å­—å…§å®¹ä¸¦ç”Ÿæˆå›æ‡‰ - å…¼å®¹æ—§ç‰ˆæœ¬"""
    return analyze_and_respond_with_context(transcript)

def analyze_and_respond_with_context(user_input, conversation_context=None, response_style='friendly', conversation_mode='continuous', conversation_round=0):
    """å¢å¼ºç‰ˆAIåˆ†æ - æ”¯æŒå¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡"""
    try:
        # æ„å»ºç³»ç»Ÿæç¤ºè¯
        system_prompt = build_system_prompt(response_style, conversation_mode, conversation_round)
        
        # æ„å»ºæ¶ˆæ¯å†å²
        messages = [{"role": "system", "content": system_prompt}]
        
        # æ·»åŠ å¯¹è¯ä¸Šä¸‹æ–‡
        if conversation_context and len(conversation_context) > 0:
            for ctx_msg in conversation_context[-6:]:  # ä¿ç•™æœ€è¿‘6æ¡æ¶ˆæ¯
                messages.append({
                    "role": ctx_msg.get('role', 'user'),
                    "content": ctx_msg.get('content', '')
                })
        
        # æ·»åŠ å½“å‰ç”¨æˆ·è¾“å…¥
        user_prompt = build_user_prompt(user_input, conversation_round, len(conversation_context) if conversation_context else 0)
        messages.append({"role": "user", "content": user_prompt})
        
        print(f"ğŸ¤– è«‹æ±‚ Message æ•¸é‡ : {len(messages)}")
        print(f"ğŸ“ ç³»çµ±æç¤º: {system_prompt[:100]}...")
        
        completion = client.chat.completions.create(
            model=MODEL_NAME,
            messages=messages,
            max_tokens=600,
            temperature=get_temperature_by_style(response_style)
        )
        
        message_content = completion.choices[0].message.content
        clean_content = message_content.replace('``` json\n', '').replace('\n ```', '')
        fixed_json = fix_incomplete_json(clean_content)
        
        try:
            data = json.loads(fixed_json)
            sentiment = data.get('sentiment', 'æœªçŸ¥')
            response = data.get('response', 'ç„¡æ³•è§£æå›æ‡‰å…§å®¹')
            confidence = data.get('confidence', 0.95)
            
            # ä¸åœ¨é€™è£¡ç”ŸæˆèªéŸ³ï¼Œæ”¹ç‚ºåœ¨voice_cloneè·¯ç”±ä¸­è™•ç†
            audio_url = None
            
            return {
                "sentiment": sentiment, 
                "response": response, 
                "confidence": confidence,
                "audio_url": audio_url
            }
                
        except json.JSONDecodeError as e:
            print(f"JSON è§£æéŒ¯èª¤: {e}")
            return {
                "sentiment": "æœªçŸ¥", 
                "response": f"JSON è§£æéŒ¯èª¤: {str(e)}", 
                "confidence": 0.5,
                "audio_url": None
            }
            
        except Exception as e:
            print(f"è™•ç†å›æ‡‰æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return {
                "sentiment": "æœªçŸ¥", 
                "response": f"è™•ç†å›æ‡‰æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}", 
                "confidence": 0.5,
                "audio_url": None
            }
    
    except Exception as e:
        print(f"OpenAI API è«‹æ±‚éŒ¯èª¤: {e}")
        return {
            "sentiment": "æœªçŸ¥", 
            "response": "ç”Ÿæˆå›æ‡‰æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹é‡è©¦ã€‚", 
            "confidence": 0.5,
            "audio_url": None
        }

def build_system_prompt(response_style, conversation_mode, conversation_round):
    """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
    base_prompt = (
        "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„ç¤¾æœƒæœå‹™çš„äººå“¡ï¼Œæ“…é•·è«®å•†è¼”å°ä¸¦å…·æœ‰è±å¯Œçš„çŸ¥è­˜èƒŒæ™¯ã€‚"
        "è«‹ä»¥åŒç†å¿ƒå’Œå°ˆæ¥­çš„æ…‹åº¦æä¾›å»ºè­°ï¼Œç‰¹åˆ¥æ³¨æ„ä½¿ç”¨é©åˆçš„ä¸­æ–‡è¡¨é”æ–¹å¼ï¼Œä¸èƒ½ä¸­è‹±æ–‡å¤¾é›œï¼Œä»¥åŠä½¿ç”¨ä¸€äº›èªåŠ©è©ã€‚"
    )
    
    # æ ¹æ®å›åº”é£æ ¼è°ƒæ•´
    style_prompts = {
        'friendly': "èªæ°£è¦å‹å¥½è¦ªåˆ‡ï¼Œåƒæœ‹å‹èˆ¬äº¤è«‡ï¼Œä½¿ç”¨å°ç£ç•¶åœ°å£èªï¼Œé¿å…éæ–¼æ­£å¼çš„æ•¬èªï¼Œä¸èƒ½ä¸­è‹±æ–‡å¤¾é›œä½¿ç”¨ã€‚",
        'professional': "ä¿æŒå°ˆæ¥­æ­£å¼çš„èªèª¿ï¼Œä½¿ç”¨æº–ç¢ºçš„å°ˆæ¥­è¡“èªï¼Œä½†è¦ç¢ºä¿ç”¨æˆ¶èƒ½ç†è§£ï¼Œä¸èƒ½ä¸­è‹±æ–‡å¤¾é›œä½¿ç”¨ã€‚",
        'casual': "ä½¿ç”¨è¼•é¬†éš¨æ„çš„èªèª¿ï¼Œå¯ä»¥é©ç•¶ä½¿ç”¨ç¶²è·¯ç”¨èªå’Œè¡¨æƒ…ç¬¦è™Ÿï¼Œä¸èƒ½ä¸­è‹±æ–‡å¤¾é›œä½¿ç”¨ã€‚",
        'detailed': "æä¾›è©³ç´°çš„è§£èªªå’Œåˆ†æï¼ŒåŒ…å«èƒŒæ™¯çŸ¥è­˜å’Œå…·é«”çš„æ“ä½œå»ºè­°ï¼Œä¸èƒ½ä¸­è‹±æ–‡å¤¾é›œä½¿ç”¨ã€‚"
    }
    
    # æ ¹æ®å¯¹è¯æ¨¡å¼è°ƒæ•´
    mode_prompts = {
        'continuous': "é€™æ˜¯ä¸€å€‹é€£çºŒå°è©±ï¼Œè«‹åƒè€ƒä¹‹å‰çš„å°è©±å…§å®¹ï¼Œä¿æŒè©±é¡Œçš„é€£è²«æ€§ã€‚",
        'qa': "é€™æ˜¯å•ç­”æ¨¡å¼ï¼Œå°ˆæ³¨æ–¼å›ç­”ç”¨æˆ¶çš„å…·é«”å•é¡Œã€‚",
        'creative': "é€™æ˜¯å‰µæ„æ¨¡å¼ï¼Œå¯ä»¥æä¾›æ›´å¤šå‰µæ–°çš„æƒ³æ³•å’Œå»ºè­°ã€‚"
    }
    
    # æ ¹æ®å¯¹è¯è½®æ¬¡è°ƒæ•´
    if conversation_round == 0:
        round_prompt = "é€™æ˜¯å°è©±çš„é–‹å§‹ï¼Œè«‹å‹å¥½åœ°æ‰“æ‹›å‘¼ä¸¦äº†è§£ç”¨æˆ¶éœ€æ±‚ã€‚"
    elif conversation_round < 3:
        round_prompt = "é€™æ˜¯å°è©±çš„å‰æœŸéšæ®µï¼Œè«‹æ·±å…¥äº†è§£ç”¨æˆ¶çš„æƒ…æ³ã€‚"
    else:
        round_prompt = "é€™æ˜¯æ·±åº¦å°è©±éšæ®µï¼Œè«‹åŸºæ–¼ä¹‹å‰çš„äº¤æµæä¾›æ›´å…·é«”çš„å»ºè­°ã€‚"
    
    full_prompt = f"{base_prompt}\n{style_prompts.get(response_style, style_prompts['friendly'])}\n{mode_prompts.get(conversation_mode, mode_prompts['continuous'])}\n{round_prompt}\nå›æ‡‰å­—æ•¸æ§åˆ¶åœ¨150-250å€‹ä¸­æ–‡å­—ä¹‹é–“ã€‚"
    
    return full_prompt

def build_user_prompt(user_input, conversation_round, context_count):
    """æ„å»ºç”¨æˆ·æç¤ºè¯"""
    if conversation_round == 0:
        context_info = "é€™æ˜¯æˆ‘å€‘å°è©±çš„é–‹å§‹ã€‚"
    else:
        context_info = f"é€™æ˜¯æˆ‘å€‘å°è©±çš„ç¬¬{conversation_round + 1}è¼ªï¼Œä¹‹å‰å·²ç¶“äº¤æµäº†{context_count}æ¢æ¶ˆæ¯ã€‚"
    
    return f"{context_info}ç”¨æˆ¶èªªï¼š\"{user_input}\"ã€‚è«‹åˆ†æç”¨æˆ¶çš„æƒ…ç·’ï¼ˆæ­£é¢ã€ä¸­æ€§ã€è² é¢ã€ç©æ¥µã€æ¶ˆæ¥µç­‰ï¼‰ï¼Œè©•ä¼°å›æ‡‰çš„ç½®ä¿¡åº¦ï¼ˆ0-1ä¹‹é–“çš„æ•¸å€¼ï¼‰ï¼Œä¸¦åŸºæ–¼å°è©±ä¸Šä¸‹æ–‡æä¾›é©ç•¶çš„å›æ‡‰ã€‚ä½¿ç”¨JSONæ ¼å¼å›æ‡‰ï¼ŒåŒ…å«sentimentã€confidenceå’Œresponseä¸‰å€‹æ¬„ä½ã€‚"

def get_temperature_by_style(response_style):
    """æ ¹æ®å›åº”é£æ ¼è·å–temperatureå‚æ•°"""
    temperature_map = {
        'friendly': 0.8,
        'professional': 0.5,
        'casual': 0.9,
        'detailed': 0.6
    }
    return temperature_map.get(response_style, 0.7)

def generate_care_message(schedule, weather_info, user_profile):
    """
    ç”Ÿæˆå®šæœŸé—œæ‡·è¨Šæ¯ï¼ˆä½¿ç”¨ DeepSeek LLMï¼‰
    
    Args:
        schedule (dict): æ’ç¨‹è³‡è¨Š
        weather_info (dict): å¤©æ°£è³‡è¨Š
        user_profile (dict): ç”¨æˆ¶è³‡æ–™
    
    Returns:
        str: é—œæ‡·è¨Šæ¯æ–‡æœ¬
    """
    try:
        # æ§‹å»ºç³»çµ±æç¤ºè©
        system_prompt = """ä½ æ˜¯ä¸€ä½æº«æš–é—œæ‡·çš„ç¤¾å·¥äººå“¡ï¼Œå°ˆé–€ç‚ºé•·è€…æä¾›å®šæœŸé—œæ‡·æœå‹™ã€‚
ä½ çš„ä»»å‹™æ˜¯ç”Ÿæˆä¸€æ®µæº«é¦¨ã€è‡ªç„¶çš„é—œæ‡·è¨Šæ¯ã€‚

è¦æ±‚ï¼š
1. èªæ°£è¦ªåˆ‡æº«æš–ï¼Œåƒå®¶äººèˆ¬é—œå¿ƒ
2. ä½¿ç”¨å°ç£ç•¶åœ°å£èªï¼Œè‡ªç„¶æµæš¢
3. æ ¹æ“šå¤©æ°£æä¾›å¯¦ç”¨å»ºè­°
4. é—œæ³¨é•·è€…çš„å¥åº·å’Œå®‰å…¨
5. å­—æ•¸æ§åˆ¶åœ¨ 150-200 å­—
6. ä¸è¦ä½¿ç”¨éæ–¼æ­£å¼çš„æ•¬èª
7. å¯ä»¥é©ç•¶ä½¿ç”¨èªåŠ©è©ï¼ˆå–”ã€å‘¢ã€å•¦ç­‰ï¼‰
8. ä¸è¦ä¸­è‹±æ–‡å¤¾é›œ"""
        
        # æ§‹å»ºç”¨æˆ¶è¨Šæ¯
        user_name = user_profile.get('full_name', 'é•·è€…')
        user_age = user_profile.get('age', '70')
        health_notes = user_profile.get('health_notes', 'è‰¯å¥½')
        
        scheduled_time = schedule.get('scheduled_time', '')
        address = schedule.get('address', 'å®¶ä¸­')
        description = schedule.get('description', '')
        
        condition = weather_info.get('condition', 'æ™´æœ—')
        temperature = weather_info.get('temperature', 25)
        
        user_message = f"""è«‹ç‚ºä»¥ä¸‹é•·è€…ç”Ÿæˆä¸€æ®µé—œæ‡·è¨Šæ¯ï¼š

é•·è€…è³‡è¨Šï¼š
- å§“åï¼š{user_name}
- å¹´é½¡ï¼š{user_age}æ­²
- å¥åº·ç‹€æ³ï¼š{health_notes}

ç•¶å‰æƒ…å¢ƒï¼š
- æ™‚é–“ï¼š{scheduled_time}
- åœ°é»ï¼š{address}
- å¤©æ°£ï¼š{condition}
- æº«åº¦ï¼š{temperature}åº¦
- ç‰¹åˆ¥æé†’ï¼š{description if description else 'ç„¡'}

è«‹ç”Ÿæˆä¸€æ®µæº«é¦¨çš„é—œæ‡·è¨Šæ¯ã€‚"""
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_message}
        ]
        
        completion = client.chat.completions.create(
            model=MODEL_NAME,
            messages=messages,
            max_tokens=400,
            temperature=0.8
        )
        
        message = completion.choices[0].message.content.strip()
        
        # ç¢ºä¿è¨Šæ¯é•·åº¦é©ä¸­ï¼ˆQwen TTS é™åˆ¶ 200 å­—ç¬¦ï¼‰
        if len(message) > 200:
            message = message[:200]
        
        return message
        
    except Exception as e:
        print(f"ç”Ÿæˆé—œæ‡·è¨Šæ¯å¤±æ•—: {e}")
        # è¿”å›é è¨­è¨Šæ¯
        return f"{user_profile.get('full_name', 'é•·è€…')}æ‚¨å¥½ï¼Œé€™æ˜¯ä¸€å‰‡æº«é¦¨çš„é—œæ‡·æé†’ã€‚ä»Šå¤©å¤©æ°£{weather_info.get('condition', 'ä¸éŒ¯')}ï¼Œæº«åº¦ç´„{weather_info.get('temperature', 25)}åº¦ï¼Œè«‹æ³¨æ„ä¿é‡èº«é«”ã€‚ç¥æ‚¨æœ‰ç¾å¥½çš„ä¸€å¤©ï¼"
