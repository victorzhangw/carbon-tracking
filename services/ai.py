import os
import json
from openai import OpenAI
from config import DEEPSEEK_API_KEY, BASE_URL, MODEL_NAME
from utils import fix_incomplete_json
from services.gpt_sovits_service import gpt_sovits_service
from database import save_voice_generation_record

# åˆå§‹åŒ–  AI å®¢æˆ¶ç«¯
client = OpenAI(
    api_key=DEEPSEEK_API_KEY,
    base_url=BASE_URL,
)

def analyze_and_respond(transcript):
    """åˆ†ææ–‡å­—å…§å®¹ä¸¦ç”Ÿæˆå›æ‡‰ - å…¼å®¹æ—§ç‰ˆæœ¬"""
    return analyze_and_respond_with_context(transcript)

def analyze_and_respond_with_context(user_input, conversation_context=None, response_style='friendly', conversation_mode='continuous', conversation_round=0):
    """å¢å¼ºç‰ˆAIåˆ†æ - æ”¯æŒå¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡"""
    try:
        # æ„å»ºç³»ç»Ÿæç¤ºè¯
        system_prompt = build_system_prompt(response_style, conversation_mode, conversation_round)
        
        # æ„å»ºæ¶ˆæ¯å†å²
        messages = [{"role": "system", "content": system_prompt}]
        
        # æ·»åŠ å¯¹è¯ä¸Šä¸‹æ–‡
        if conversation_context and len(conversation_context) > 0:
            for ctx_msg in conversation_context[-6:]:  # ä¿ç•™æœ€è¿‘6æ¡æ¶ˆæ¯
                messages.append({
                    "role": ctx_msg.get('role', 'user'),
                    "content": ctx_msg.get('content', '')
                })
        
        # æ·»åŠ å½“å‰ç”¨æˆ·è¾“å…¥
        user_prompt = build_user_prompt(user_input, conversation_round, len(conversation_context) if conversation_context else 0)
        messages.append({"role": "user", "content": user_prompt})
        
        print(f"ğŸ¤– è«‹æ±‚ Message æ•¸é‡ : {len(messages)}")
        print(f"ğŸ“ ç³»çµ±æç¤º: {system_prompt[:100]}...")
        
        completion = client.chat.completions.create(
            model=MODEL_NAME,
            messages=messages,
            max_tokens=600,
            temperature=get_temperature_by_style(response_style)
        )
        
        message_content = completion.choices[0].message.content
        clean_content = message_content.replace('``` json\n', '').replace('\n ```', '')
        fixed_json = fix_incomplete_json(clean_content)
        
        try:
            data = json.loads(fixed_json)
            sentiment = data.get('sentiment', 'æœªçŸ¥')
            response = data.get('response', 'ç„¡æ³•è§£æå›æ‡‰å…§å®¹')
            confidence = data.get('confidence', 0.95)
            
            # ä¸åœ¨é€™è£¡ç”ŸæˆèªéŸ³ï¼Œæ”¹ç‚ºåœ¨voice_cloneè·¯ç”±ä¸­è™•ç†
            audio_url = None
            
            return {
                "sentiment": sentiment, 
                "response": response, 
                "confidence": confidence,
                "audio_url": audio_url
            }
                
        except json.JSONDecodeError as e:
            print(f"JSON è§£æéŒ¯èª¤: {e}")
            return {
                "sentiment": "æœªçŸ¥", 
                "response": f"JSON è§£æéŒ¯èª¤: {str(e)}", 
                "confidence": 0.5,
                "audio_url": None
            }
            
        except Exception as e:
            print(f"è™•ç†å›æ‡‰æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return {
                "sentiment": "æœªçŸ¥", 
                "response": f"è™•ç†å›æ‡‰æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}", 
                "confidence": 0.5,
                "audio_url": None
            }
    
    except Exception as e:
        print(f"OpenAI API è«‹æ±‚éŒ¯èª¤: {e}")
        return {
            "sentiment": "æœªçŸ¥", 
            "response": "ç”Ÿæˆå›æ‡‰æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹é‡è©¦ã€‚", 
            "confidence": 0.5,
            "audio_url": None
        }

def build_system_prompt(response_style, conversation_mode, conversation_round):
    """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
    base_prompt = (
        "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„ç¤¾æœƒæœå‹™çš„äººå“¡ï¼Œæ“…é•·è«®å•†è¼”å°ä¸¦å…·æœ‰è±å¯Œçš„çŸ¥è­˜èƒŒæ™¯ã€‚"
        "è«‹ä»¥åŒç†å¿ƒå’Œå°ˆæ¥­çš„æ…‹åº¦æä¾›å»ºè­°ï¼Œç‰¹åˆ¥æ³¨æ„ä½¿ç”¨é©åˆçš„ä¸­æ–‡è¡¨é”æ–¹å¼ï¼Œä¸èƒ½ä¸­è‹±æ–‡å¤¾é›œï¼Œä»¥åŠä½¿ç”¨ä¸€äº›èªåŠ©è©ã€‚"
    )
    
    # æ ¹æ®å›åº”é£æ ¼è°ƒæ•´
    style_prompts = {
        'friendly': "èªæ°£è¦å‹å¥½è¦ªåˆ‡ï¼Œåƒæœ‹å‹èˆ¬äº¤è«‡ï¼Œä½¿ç”¨å°ç£ç•¶åœ°å£èªï¼Œé¿å…éæ–¼æ­£å¼çš„æ•¬èªï¼Œä¸èƒ½ä¸­è‹±æ–‡å¤¾é›œä½¿ç”¨ã€‚",
        'professional': "ä¿æŒå°ˆæ¥­æ­£å¼çš„èªèª¿ï¼Œä½¿ç”¨æº–ç¢ºçš„å°ˆæ¥­è¡“èªï¼Œä½†è¦ç¢ºä¿ç”¨æˆ¶èƒ½ç†è§£ï¼Œä¸èƒ½ä¸­è‹±æ–‡å¤¾é›œä½¿ç”¨ã€‚",
        'casual': "ä½¿ç”¨è¼•é¬†éš¨æ„çš„èªèª¿ï¼Œå¯ä»¥é©ç•¶ä½¿ç”¨ç¶²è·¯ç”¨èªå’Œè¡¨æƒ…ç¬¦è™Ÿï¼Œä¸èƒ½ä¸­è‹±æ–‡å¤¾é›œä½¿ç”¨ã€‚",
        'detailed': "æä¾›è©³ç´°çš„è§£èªªå’Œåˆ†æï¼ŒåŒ…å«èƒŒæ™¯çŸ¥è­˜å’Œå…·é«”çš„æ“ä½œå»ºè­°ï¼Œä¸èƒ½ä¸­è‹±æ–‡å¤¾é›œä½¿ç”¨ã€‚"
    }
    
    # æ ¹æ®å¯¹è¯æ¨¡å¼è°ƒæ•´
    mode_prompts = {
        'continuous': "é€™æ˜¯ä¸€å€‹é€£çºŒå°è©±ï¼Œè«‹åƒè€ƒä¹‹å‰çš„å°è©±å…§å®¹ï¼Œä¿æŒè©±é¡Œçš„é€£è²«æ€§ã€‚",
        'qa': "é€™æ˜¯å•ç­”æ¨¡å¼ï¼Œå°ˆæ³¨æ–¼å›ç­”ç”¨æˆ¶çš„å…·é«”å•é¡Œã€‚",
        'creative': "é€™æ˜¯å‰µæ„æ¨¡å¼ï¼Œå¯ä»¥æä¾›æ›´å¤šå‰µæ–°çš„æƒ³æ³•å’Œå»ºè­°ã€‚"
    }
    
    # æ ¹æ®å¯¹è¯è½®æ¬¡è°ƒæ•´
    if conversation_round == 0:
        round_prompt = "é€™æ˜¯å°è©±çš„é–‹å§‹ï¼Œè«‹å‹å¥½åœ°æ‰“æ‹›å‘¼ä¸¦äº†è§£ç”¨æˆ¶éœ€æ±‚ã€‚"
    elif conversation_round < 3:
        round_prompt = "é€™æ˜¯å°è©±çš„å‰æœŸéšæ®µï¼Œè«‹æ·±å…¥äº†è§£ç”¨æˆ¶çš„æƒ…æ³ã€‚"
    else:
        round_prompt = "é€™æ˜¯æ·±åº¦å°è©±éšæ®µï¼Œè«‹åŸºæ–¼ä¹‹å‰çš„äº¤æµæä¾›æ›´å…·é«”çš„å»ºè­°ã€‚"
    
    full_prompt = f"{base_prompt}\n{style_prompts.get(response_style, style_prompts['friendly'])}\n{mode_prompts.get(conversation_mode, mode_prompts['continuous'])}\n{round_prompt}\nå›æ‡‰å­—æ•¸æ§åˆ¶åœ¨150-250å€‹ä¸­æ–‡å­—ä¹‹é–“ã€‚"
    
    return full_prompt

def build_user_prompt(user_input, conversation_round, context_count):
    """æ„å»ºç”¨æˆ·æç¤ºè¯"""
    if conversation_round == 0:
        context_info = "é€™æ˜¯æˆ‘å€‘å°è©±çš„é–‹å§‹ã€‚"
    else:
        context_info = f"é€™æ˜¯æˆ‘å€‘å°è©±çš„ç¬¬{conversation_round + 1}è¼ªï¼Œä¹‹å‰å·²ç¶“äº¤æµäº†{context_count}æ¢æ¶ˆæ¯ã€‚"
    
    return f"{context_info}ç”¨æˆ¶èªªï¼š\"{user_input}\"ã€‚è«‹åˆ†æç”¨æˆ¶çš„æƒ…ç·’ï¼ˆæ­£é¢ã€ä¸­æ€§ã€è² é¢ã€ç©æ¥µã€æ¶ˆæ¥µç­‰ï¼‰ï¼Œè©•ä¼°å›æ‡‰çš„ç½®ä¿¡åº¦ï¼ˆ0-1ä¹‹é–“çš„æ•¸å€¼ï¼‰ï¼Œä¸¦åŸºæ–¼å°è©±ä¸Šä¸‹æ–‡æä¾›é©ç•¶çš„å›æ‡‰ã€‚ä½¿ç”¨JSONæ ¼å¼å›æ‡‰ï¼ŒåŒ…å«sentimentã€confidenceå’Œresponseä¸‰å€‹æ¬„ä½ã€‚"

def get_temperature_by_style(response_style):
    """æ ¹æ®å›åº”é£æ ¼è·å–temperatureå‚æ•°"""
    temperature_map = {
        'friendly': 0.8,
        'professional': 0.5,
        'casual': 0.9,
        'detailed': 0.6
    }
    return temperature_map.get(response_style, 0.7)
